<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Eita-nakamura.GitHub.io : ">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Publications</title>

   <style>
      ul.pub {line-height: 20px;}
      ul.pub li {margin-bottom: 10px;}
      ol.pub {line-height: 20px;}
      ol.pub li {margin-bottom: 10px;}
    </style>

    <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-80849161-1', 'auto');
    ga('send', 'pageview');

    </script>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">Publications and Talks　　 <a href="http://eita-nakamura.github.io"><font size="5" color="wheat">Back to main page</font></a></h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <h5><a href="eita-nakamura_publications-ja.html">Publications in Japanese/日本語の発表文献はこちら</a></h5>

        <h3><font color="#990000">Journal Papers</font></h3>
        <ol class="pub" reversed>

<li>Eita Nakamura, Yasuyuki Saito, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><font color="#222222">Statistical Learning and Estimation of Piano Fingering</font></a></strong> <a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing</em> <a href="https://arxiv.org/abs/1904.10237" target="_blank"><font color="#808080">[arXiv:1904.10237]</font></a>

<li>Hiroaki Tsushima, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Bayesian Melody Harmonization Based on a Tree-Structured Generative Model of Chord Sequences and Melodies</font></strong><br>
<em>Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing</em>

<li>Eita Nakamura, Kunihiko Kaneko<br>
<strong><a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><font color="#222222">Statistical Evolutionary Laws in Music Styles</font></a></strong> <a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<a href="https://arxiv.org/abs/1809.05832" target="_blank"><font color="#808080">[arXiv:1809.05832]</font></a>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><font color="#222222">Statistical Piano Reduction Controlling Performance Difficulty</font></a></strong> <a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1017/ATSIP.2018.18" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 7, No. e13, pp. 1–12, 2018. <a href="https://arxiv.org/abs/1808.05006" target="_blank"><font color="#808080">[arXiv:1808.05006]</font> <a href="./citations/2018PianoReduction.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3DBA1E441E9EACB1DE3EF730D92B84C3/S2048770318000173a.pdf/chordaware_automatic_music_transcription_based_on_hierarchical_bayesian_integration_of_acoustic_and_language_models.pdf" target="_blank"><font color="#222222">Chord-Aware Automatic Music Transcription Based on Hierarchical Bayesian Integration of Acoustic and Language Models</font></a></strong> <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3DBA1E441E9EACB1DE3EF730D92B84C3/S2048770318000173a.pdf/chordaware_automatic_music_transcription_based_on_hierarchical_bayesian_integration_of_acoustic_and_language_models.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1017/ATSIP.2018.17" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 7, No. e14, pp. 1–14, 2018. <a href="./citations/2018MultipitchEstimationWithLanguageModel.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><font color="#222222">Generative Statistical Models with Self-Emergent Grammar of Chord Sequences</font></a></strong> <a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://www.tandfonline.com/doi/abs/10.1080/09298215.2018.1447584?journalCode=nnmr20" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 47, No. 3, pp. 226–248, 2018. <a href="https://arxiv.org/abs/1708.02255" target="_blank"><font color="#808080">[arXiv:1708.02255]</font> <a href="./citations/2018ChordModel.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><font color="#222222">Bayesian Multichannel Audio Source Separation Based on Integrated Source and Spatial Models</font></a></strong> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2789320" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 26, No. 4, pp. 1–16, 2018. <a href="./citations/2018BayesianMNMF.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><font color="#222222">Note Value Recognition for Piano Transcription Using Markov Random Fields</font></a></strong> <a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2722103" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a> <a href="https://anonymous574868.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 9, pp. 1846–1858, 2017. <a href="https://arxiv.org/abs/1703.08144" target="_blank"><font color="#808080">[arXiv:1703.08144]</font></a> <a href="./citations/2017NoteValueRecognition.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices</font></a></strong> <a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2662479" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a> <a href="http://anonymous4721029.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 4, pp. 794-806, 2017. <a href="https://arxiv.org/abs/1701.08343" target="_blank"><font color="#808080">[arXiv:1701.08343]</font></a> <a href="./citations/2017PolyphonicRhythmTranscription.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Misato Ohkita, Yoshiaki Bando, Yukara Ikemiya, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong></strong>
<strong><a href="./articles/Ohkita_etal_DancingRobot_2017.pdf" target="_blank"><font color="#222222">Audio-Visual Beat Tracking Based on a State-Space Model for a Robot Dancer Performing with a Human Dancer</font></a></strong> <a href="./articles/Ohkita_etal_DancingRobot_2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://www.fujipress.jp/jrm/rb/robot002900010125/" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of Robotics and Mechatronics</em>, Vol. 29, No. 1, pp. 125-136, 2017. <a href="./citations/2017DancingRobot.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><font color="#222222">Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips</font></a></strong> <a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://dx.doi.org/10.1109/TASLP.2015.2507862" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 24, No. 2, pp. 329-339, 2016. <a href="https://arxiv.org/abs/1512.07748" target="_blank"><font color="#808080">[arXiv:1512.07748]</font></a> <a href="./citations/2016AudioScofo.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama, Kenji Watanabe<br>
<strong><a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><font color="#222222">A Stochastic Temporal Model of Polyphonic MIDI Performance with Ornaments</font></a></strong> <a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.tandfonline.com/doi/full/10.1080/09298215.2015.1078819" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 44, No. 4, pp. 287-304, 2015. <a href="https://arxiv.org/abs/1404.2314" target="_blank"><font color="#808080">[arXiv:1404.2314]</font></a> <a href="./citations/2014OrnamentModel.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Tomohiko Nakamura, Yasuyuki Saito, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="http://arxiv.org/pdf/1404.2313v1.pdf" target="_blank"><font color="#222222">Outer-Product Hidden Markov Model and Polyphonic MIDI Score Following</font></a></strong> <a href="http://arxiv.org/pdf/1404.2313v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.tandfonline.com/doi/abs/10.1080/09298215.2014.884145#.VStjU6aR1lJ" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 43, No. 2, pp. 183-201, 2014. <a href="https://arxiv.org/abs/1404.2313" target="_blank"><font color="#808080">[arXiv:1404.2313]</font></a> <a href="./citations/2014OuterProductHMM.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Haruto Takeda, Ryuichi Yamamoto, Yasuyuki Saito, Shinji Sako, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><font color="#222222">Score Following Handling Performances with Arbitrary Repeats and Skips and Automatic Accompaniment</font></a></strong> (in Japanese) <a href="./articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=91580&item_no=1&page_id=13&block_id=8" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of Information Processing Society of Japan</em>, Vol. 54, No. 4, pp. 1338-1349, 2013.

<li>Shoji Asai, Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/1202.3584v2.pdf" target="_blank"><font color="#222222">Discriminating Minimal SUGRA and Minimal Gauge Mediation Models at the Early LHC</font></a></strong> <a href="https://arxiv.org/pdf/1202.3584v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://link.springer.com/article/10.1007%2FJHEP04(2012)003" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1204, No. 003, pp. 1-22, 2012. <a href="https://arxiv.org/abs/1202.3584" target="_blank"><font color="#808080">[arXiv:1202.3584]</font></a>

<li>Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/1010.5995v3.pdf" target="_blank"><font color="#222222">Discovery Potential for Low-Scale Gauge Mediation at Early LHC</font></a></strong> <a href="https://arxiv.org/pdf/1010.5995v3.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://link.springer.com/article/10.1007%2FJHEP03(2011)115" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1103, No. 115, pp. 1-15, 2011. <a href="https://arxiv.org/abs/1010.5995" target="_blank"><font color="#808080">[arXiv:1010.5995]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0912.1683v1.pdf" target="_blank"><font color="#222222">Low-Scale Gauge Mediation and Composite Messenger Dark Matter</font></a></strong> <a href="https://arxiv.org/pdf/0912.1683v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://link.springer.com/article/10.1007%2FJHEP04(2010)119" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1004, No. 119, pp. 1-14, 2010. <a href="https://arxiv.org/abs/0912.1683" target="_blank"><font color="#808080">[arXiv:0912.1683]</font></a>

<li>Koichi Hamaguchi, Kouhei Nakaji, Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/0905.1574v1.pdf" target="_blank"><font color="#222222">Inverse Problem of Cosmic-Ray Electron/Positron from Dark Matter</font></a></strong> <a href="https://arxiv.org/pdf/0905.1574v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.sciencedirect.com/science/article/pii/S0370269309010065" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 680, pp. 172-178, 2009. <a href="https://arxiv.org/abs/0905.1574" target="_blank"><font color="#808080">[arXiv:0905.1574]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><font color="#222222">Decaying Dark Matter Baryons in a Composite Messenger Model</font></a></strong> <a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.sciencedirect.com/science/article/pii/S0370269309003013" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 674, pp. 299-302, 2009. <a href="https://arxiv.org/abs/0811.0737" target="_blank"><font color="#808080">[arXiv:0811.0737]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/0805.2502v1.pdf" target="_blank"><font color="#222222">A Measurement of Neutralino Mass at the LHC in Light Gravitino Scenarios</font></a></strong> <a href="https://arxiv.org/pdf/0805.2502v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.sciencedirect.com/science/article/pii/S037026930800782X" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 666, pp. 57-61, 2008. <a href="https://arxiv.org/abs/0805.2502" target="_blank"><font color="#808080">[arXiv:0805.2502]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0804.3296v2.pdf" target="_blank"><font color="#222222">Strongly Interacting Gauge Mediation at the LHC</font></a></strong> <a href="https://arxiv.org/pdf/0804.3296v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://iopscience.iop.org/1126-6708/2008/07/107" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 0807, No. 107, pp. 1-11, 2008. <a href="https://arxiv.org/abs/0804.3296" target="_blank"><font color="#808080">[arXiv:0804.3296]</font></a>

        </ol>

        <h3><font color="#990000">Conference Talks (Refereed)</font></h3>

        <ol class="pub" reversed>

<li>Eita Nakamura, Kentaro Shibata, Ryo Nishikimi, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nakamura_etal_StatisticalMelodyArrangement_ICASSP2019.pdf" target="_blank"><font color="#222222">Unsupervised Melody Style Conversion</font></a></strong> <a href="./articles/Nakamura_etal_StatisticalMelodyArrangement_ICASSP2019.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 196-200, May 2019.

<li>Kentaro Shibata, Ryo Nishikimi, Satoru Fukayama, Masataka Goto, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Joint Transcription of Lead, Bass, and Rhythm Guitars Based on a Factorial Hidden Semi-Markov Model</font></strong><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, to be presented, May, 2019.

<li>Andrew McLeod, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Improved Metrical Alignment of MIDI Performance Based on a Repetition-Aware Online-Adapted Grammar</font></strong><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, to be presented, May, 2019.

<li>Ryo Nishikimi, Eita Nakamura, Satoru Fukayama, Masataka Goto, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Automatic Singing Transcription Based on Encoder-Decoder Recurrent Neural Networks with a Weakly-Supervised Attention Mechanism</font></strong><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, to be presented, May, 2019.

<li>Shun Ueda, Kentaro Shibata, Yusuke Wada, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Bayesian Drum Transcription Based on Nonnegative Matrix Factor Decomposition with a Deep Score Prior</font></strong><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, to be presented, May, 2019.

<li>Eita Nakamura, Ryo Nishikimi, Simon Dixon, Kazuyoshi Yoshii<br>
<strong><a href="./articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><font color="#222222">Probabilistic Sequential Patterns for Singing Transcription</font></a></strong> <a href="./articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, pp. 1905-1912, November 2018.

<li>Yusuke Wada, Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Wada_etal_SingingF0GenerationByWaveNet_2018.pdf" target="_blank"><font color="#222222">Sequential Generation of Singing F0 Contours from Musical Note Sequences Based on WaveNet</font></a></strong> <a href="./articles/Wada_etal_SingingF0GenerationByWaveNet_2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, pp. 983-989, November 2018.

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Tsushima_etal_InteractiveArrangement_ISMIR2018.pdf" target="_blank"><font color="#222222">Interactive Arrangement of Chords and Melodies Based on a Tree-Structured Generative Model</font></a></strong> <a href="./articles/Tsushima_etal_InteractiveArrangement_ISMIR2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 19th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 145-151, September 2018.

<li>Kazuyoshi Yoshii, Koichi Kitamura, Yoshiaki Bando, Eita Nakamura, Tatsuya Kawahara<br>
<strong><font color="#222222">Independent Low-Rank Tensor Analysis for Audio Source Separation</font></strong><br>
<em>Proc. 26th European Signal Processing Conference (EUSIPCO)</em>, September 2018.

<li>Yasuyuki Saito, Yasuji Sakai, Yuu Igarashi, Eita Nakamura, Suguru Agata, Shigeki Sagayama<br>
<strong><font color="#222222">Automatic Music Accompaniment Technology Applied to Recreational Singing Activities at Long-Term Health-Care Facilities</font></strong><br>
<em>Proc. 3rd Computer Simulation of Musical Creativity Conference (CSMC)</em>, August 2018.

<li>Mitsuyo Hashida, Eita Nakamura, Haruhiro Katayose<br>
<strong><a href="./articles/Hashida_etal_CrestMusePEDB2ndEd_SMC2018.pdf" target="_blank"><font color="#222222">CrestMusePEDB 2nd Edition: Music Performance Database with Phrase Information</font></a></strong> <a href="./articles/Hashida_etal_CrestMusePEDB2ndEd_SMC2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Sound and Music Computing Conference (SMC)</em>, July 2018.

<li>Eita Nakamura, Emmanouil Benetos, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="./articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><font color="#222222">Towards Complete Polyphonic Music Transcription: Integrating Multi-Pitch Detection and Rhythm Quantization</font></a></strong> <a href="./articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 43rd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 101-105, April, 2018.

<li>Kazuyoshi Yoshii, Eita Nakamura, Katsutoshi Itoyama, Masataka Goto<br>
<strong><a href="./articles/Yoshii_etal_InfiniteProbabilisticLatentComponentAnalysisForAudioSourceSeparation_2017.pdf" target="_blank"><font color="#222222">Infinite Probabilistic Latent Component Analysis For Audio Source Separation</font></a></strong> <a href="./articles/Yoshii_etal_InfiniteProbabilisticLatentComponentAnalysisForAudioSourceSeparation_2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 18th IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em>, pp. 347-353, 2017. 

<li>Eita Nakamura, Kazuyoshi Yoshii, Haruhiro Katayose<br>
<strong><a href="./articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><font color="#222222">Performance Error Detection and Post-Processing for Fast and Accurate Symbolic Music Alignment</font></a></strong> <a href="./articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://midialignment.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 347-353, 2017.

<li>Ryo Nishikimi, Eita Nakamura, Masataka Goto, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nishikimi_etal_ScaleAndRhythmAwareMusicalNoteEstimationForVocalF0_ISMIR2017.pdf" target="_blank"><font color="#222222">Scale- and Rhythm-Aware Musical Note Estimation for Vocal F0 Trajectories Based on a Semi-Tatum-Synchronous Hierarchical Hidden Semi-Markov Model</font></a></strong> <a href="./articles/Nishikimi_etal_ScaleAndRhythmAwareMusicalNoteEstimationForVocalF0_ISMIR2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://sap.ist.i.kyoto-u.ac.jp/members/nishikimi/demo/ismir2017/" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 376-382, 2017.

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Tsushima_etal_MelodyHarmonization_ISMIR2017.pdf" target="_blank"><font color="#222222">Function- and Rhythm-Aware Melody Harmonization Based on Tree-Structured Parsing and Split-Merge Sampling of Chord Sequences</font></a></strong> <a href="./articles/Tsushima_etal_MelodyHarmonization_ISMIR2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://anonym9329.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 502-508, 2017.

<li>Yusuke Wada, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Wada_etal_AdaptiveKaraokeSystem_SMC2017.pdf" target="_blank"><font color="#222222">An Adaptive Karaoke System that Plays Accompaniment Parts of Music Audio Signals Synchronously with Users' Singing Voices</font></a></strong> <a href="./articles/Wada_etal_AdaptiveKaraokeSystem_SMC2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://sap.ist.i.kyoto-u.ac.jp/members/wada/smc2017/index.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 14th Sound and Music Computing Conference (SMC)</em>, pp. 110-116, 2017.

<li>Mitsuyo Hashida, Eita Nakamura, Haruhiro Katayose<br>
<strong><a href="./articles/Hashida_etal_ConstructingPEDB2ndEdition_SMC2017.pdf" target="_blank"><font color="#222222">Constructing PEDB 2nd Edition: A Music Performance Database with Phrase Information</font></a></strong> <a href="./articles/Hashida_etal_ConstructingPEDB2ndEdition_SMC2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 14th Sound and Music Computing Conference (SMC)</em>, pp. 359-364, 2017.

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong><a href="./articles/Itakura_etal_BayesianMultichannelNMFForAudioSourceSeparation_ICASSP2017.pdf" target="_blank"><font color="#222222">Bayesian Multichannel Nonnegative Matrix Factorization for Audio Source Separation and Localization</font></a></strong> <a href="./articles/Itakura_etal_BayesianMultichannelNMFForAudioSourceSeparation_ICASSP2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://ieeexplore.ieee.org/document/7952216/" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 551-555, 2017.

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_RhythmTranscriptionOfPolyphonicMIDIPerformances_SMC2016.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic MIDI Performances Based on a Merged-Output HMM for Multiple Voices</font></a></strong> <a href="./articles/Nakamura_etal_RhythmTranscriptionOfPolyphonicMIDIPerformances_SMC2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://anonymous4721029.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 13th Sound and Music Computing Conference (SMC)</em>, pp. 338-343, 2016.

<li>Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><font color="#222222">Rhythm Transcription of MIDI Performances Based on Hierarchical Bayesian Modelling of Repetition and Modification of Musical Note Patterns</font></a></strong> <a href="./articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 24th European Signal Processing Conference (EUSIPCO)</em>, pp. 1946-1950, 2016.

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Itakura_etal_AUnifiedBayesianModelForMultichannelSourceSeparation_EUSIPCO2016.pdf" target="_blank"><font color="#222222">A Unified Bayesian Model of Time-Frequency Clustering and Low-Rank Approximation for Multi-Channel Source Separation</font></a></strong> <a href="./articles/Itakura_etal_AUnifiedBayesianModelForMultichannelSourceSeparation_EUSIPCO2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 24th European Signal Processing Conference (EUSIPCO)</em>, pp. 2280-2284, 2016.

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Ojima_etal_AHierarchicalBayesianModelOfChordsPitchesAndSpectrograms_ISMIR2016.pdf" target="_blank"><font color="#222222">A Hierarchical Bayesian Model of Chords, Pitches, and Spectrograms for Multipitch Analysis</font></a></strong> <a href="./articles/Ojima_etal_AHierarchicalBayesianModelOfChordsPitchesAndSpectrograms_ISMIR2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 17th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 309-315, 2016. 

<li>Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nishikimi_etal_MusicalNoteEstimationForF0TrajectoriesOfSingingVoices_ISMIR2016.pdf" target="_blank"><font color="#222222">Musical Note Estimation for F0 Trajectories of Singing Voices Based on a Bayesian Semi-Beat-Synchronous HMM</font></a></strong> <a href="./articles/Nishikimi_etal_MusicalNoteEstimationForF0TrajectoriesOfSingingVoices_ISMIR2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 17th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 461-467, 2016. 

<li>Yasuyuki Saito, Eita Nakamura, Riku Sato, Suguru Agata, Yuu Igarashi, Shigeki Sagayama<br>
<strong><a href="./articles/Saito_etal_ConversionFromStandardMIDIFilesToVerticalLineNationaScores_2016.pdf" target="_blank"><font color="#222222">Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners</font></a></strong> <a href="./articles/Saito_etal_ConversionFromStandardMIDIFilesToVerticalLineNationaScores_2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 2nd International Conference on Technologies for Music Notation and Representation (TENOR)</em>, pp. 200-211, 2016.

<li>Eita Nakamura, Masatoshi Hamanaka, Keiji Hirata, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nakamura_etal_TreeStructuredProbabilisticModel_ICASSP2016.pdf" target="_blank"><font color="#222222">Tree-Structured Probabilistic Model of Monophonic Written Music Based on the Generative Theory of Tonal Music</font></a></strong> <a href="./articles/Nakamura_etal_TreeStructuredProbabilisticModel_ICASSP2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 276-280, 2016.

<li>Eita Nakamura, Philippe Cuvillier, Arshia Cont, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_ARHSMMForScoreFollowing_ISMIR2015.pdf" target="_blank"><font color="#222222">Autoregressive Hidden Semi-Markov Model of Symbolic Music Performance for Score Following</font></a></strong> <a href="./articles/Nakamura_etal_ARHSMMForScoreFollowing_ISMIR2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://ismir2015.uma.es/articles/15_Paper.pdf" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 16th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 392-398, 2015.

<li>Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><font color="#222222">Automatic Piano Reduction from Ensemble Scores Based on Merged-Output Hidden Markov Model</font></a></strong> <a href="./articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://quod.lib.umich.edu/i/icmc/bbp2372.2015.060/" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 41st International Computer Music Conference (ICMC)</em>, pp. 298-305, 2015.

<li>Eita Nakamura, Shinji Takaki<br>
<strong><a href="./articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><font color="#222222">Characteristics of Polyphonic Music Style and Markov Model of Pitch-Class Intervals</font></a></strong> <a href="./articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://link.springer.com/chapter/10.1007/978-3-319-20603-5_10" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 5th Mathematics and Computation in Music (MCM)</em>, pp. 109-114, 2015.

<li>Riku Sato, Yasuyuki Saito, Suguru Agata, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="./articles/Sato_etal_AutomaticGenerationOfMusicalScoreInVerticalLineNotationFromMIDIFile_2015.pdf" target="_blank"><font color="#222222">Automatic Generation of Musical Score in Vertical Line Notation from MIDI File</font></a></strong> <a href="./articles/Sato_etal_AutomaticGenerationOfMusicalScoreInVerticalLineNotationFromMIDIFile_2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 1st International Conference on Advanced Imaging (ICAI)</em>, T105-04, pp. 559-562, 2015.

<li>Haruka Jibiki, Toshikazu Shimizu, Yasuyuki Saito, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="./articles/Jibiki_etal_AStudyOfAutomaticPageTurningOfMusicalScores_2015.pdf" target="_blank"><font color="#222222">A Study of Automatic Page Turning of Musical Scores by Detecting Player's Nods</font></a></strong> <a href="./articles/Jibiki_etal_AStudyOfAutomaticPageTurningOfMusicalScores_2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 1st International Conference on Advanced Imaging (ICAI)</em>, PB1-08, pp. 272-275, 2015.

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><font color="#222222">Merged-Output HMM for Piano Fingering of Both Hands</font></a></strong> <a href="./articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T096_251_Paper.pdf" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 15th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 531-536, 2014.

<li>Eita Nakamura, Yasuyuki Saito, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_MergedOutputHiddenMarkovModelForScoreFollowing_2014.pdf" target="_blank"><font color="#222222">Merged-Output Hidden Markov Model for Score Following of MIDI Performance with Ornaments, Desynchronized Voices, Repeats and Skips</font></a></strong> <a href="./articles/Nakamura_etal_MergedOutputHiddenMarkovModelForScoreFollowing_2014.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://hdl.handle.net/2027/spo.bbp2372.2014.182" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. Joint 40th International Computer Music Conference (ICMC) | 11th Sound and Music Computing Conference (SMC)</em>, pp. 1185-1192, 2014.

<li>Shigeki Sagayama, Tomohiko Nakamura, Eita Nakamura, Yasuyuki Saito, Hirokazu Kameoka, Nobutaka Ono<br>
<strong><a href="./articles/Sagayama_etal_AutomaticMuiscAccompanimentAllowingErrorsAndArbitraryRepeatsAndJumps_2014.pdf" target="_blank"><font color="#222222">Automatic Music Accompaniment Allowing Errors and Arbitrary Repeats and Jumps</font></a></strong> <a href="./articles/Sagayama_etal_AutomaticMuiscAccompanimentAllowingErrorsAndArbitraryRepeatsAndJumps_2014.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://scitation.aip.org/content/asa/journal/poma/21/1/10.1121/1.4904932" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 167th Meeting of Acoustical Society of America (ASA)</em>, POMA Vol. 21 No. 035003, pp. 1-11, 2014. <font color="#ff0080">(Invited Talk)</font>

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_AcousticScoreFollowingToMusicalPerformanceWithErrorsAndArbitraryRepeatsAndSkips_2014.pdf" target="_blank"><font color="#222222">Acoustic Score Following to Musical Performance with Errors and Arbitrary Repeats and Skips for Automatic Accompaniment</font></a></strong> <a href="./articles/Nakamura_etal_AcousticScoreFollowingToMusicalPerformanceWithErrorsAndArbitraryRepeatsAndSkips_2014.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://smcnetwork.org/system/files/ACOUSTIC%20SCORE%20FOLLOWING%20TO%20MUSICAL%20PERFORMANCE%20WITH%20ERRORS%20AND%20ARBITRARY%20REPEATS%20AND%20SKIPS%20FOR%20AUTOMATIC%20ACCOMPANIMENT.pdf" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 10th Sound and Music Computing Conference (SMC)</em>, pp. 1185-1192, 2014.

        </ol>

        <h3><font color="#990000">Conference Talks (Unrefereed)</font></h3>

        <ol class="pub" reversed>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong>Comparative Evaluation of Rhythm Transcription Algorithms on Polyphonic Piano Datasets</strong><br>
<em>Digital Music Research Network Workshop 2016 (DMRN+11)</em>.

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Hierarchical Bayesian Unification Model of Music Audio and Language for Multiptich Analysis and Chord Structure Induction from Audio Signals</strong> (in Japanese)<br>
<em>19th Information-Based Induction Sciences Workshop (IBIS2016)</em>, T2-23, 2016. <font color="#ff0080">(Student Presentation Award)</font>

<li>Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Semi-Beat-Synchronous Segmental HMM for Automatic Transcription from Singing Voice F0 Trajectories</strong> (in Japanese)<br>
<em>19th Information-Based Induction Sciences Workshop (IBIS2016)</em>, T2-24, 2016.

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong>Nested Bayesian Mixture-Factor Model Based on Low-Rank Sound Source Modelling and Sparse Composition Process for Multichannel Audio Source Separation</strong> (in Japanese)<br>
<em>19th Information-Based Induction Sciences Workshop (IBIS2016)</em>, T2-26, 2016. [<a href="/articles/板倉他_マルチチャネル音源分離のためのモデル.pdf">PDF</a>]

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong>Time-Frequency Clustering Based on Nested Basis-Source Mixture Modelling for Multichannel Audio Source Separation</strong> (in Japanese)<br>
<em>Technical Report of IEICE</em>, Vol. 116, No. 189, SP2016-31, pp. 25-28, 2016. <font color="#ff0080">(Student Poster Award)</font> [<a href="/articles/板倉他_マルチチャネル音源分離.pdf">PDF</a>]

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>A Hierarchical Bayesian Model of Key, Chords, Pitches, and Spectrograms for Multipitch Analysis</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 6, pp. 1-8, 2016. [<a href="/articles/Ojima_etal_MultipitchAnalysis_SIGMUS112.pdf">PDF</a>]

<li>Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Musical Note Estimation for Singing Voice F0 Trajectories Based on a Bayesian Semi-Beat-Synchronous HMM</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 7, pp. 1-7, 2016. [<a href="/articles/Nishikimi_etal_BayesianSemiBeatSynchronousHMM_SIGMUS112.pdf">PDF</a>]

<li>Haruka Jibiki, Yasuyuki Saito, Eita Nakamura, Shigeki Sagayama<br>
<strong>Discrimination of Player's Cue and Head Shaking for Automatic Page Turning System for Musical Scores</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 12, pp. 1-5, 2016. [<a href="/articles/Jibiki_etal_ScorePageTurning_SIGMUS112.pdf">PDF</a>]

<li>Riku Sato, Eita Nakamura, Yasuyuki Saito, Suguru Agata, Yuu Igarashi, Shigeki Sagayama<br>
<strong>Automatic Creation of Score in Vertical Line Notation and Piano Fingering for Beginner Player from SMF</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 13, pp. 1-6, 2016. [<a href="/articles/Sato_etal_VerticalLineNotation_SIGMUS112.pdf">PDF</a>]

<li>Ami Nagano, Yasuyuki Saito, Eita Nakamura, Shigeki Sagayama<br>
<strong>Tempo Control for Automatic Accompaniment While Player Rests in Musical Score</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 17, pp. 1-6, 2016. [<a href="/articles/Nagano_etal_TempoControlForAutomaticAccompaniment_SIGMUS112.pdf">PDF</a>]

<li>Kazuyoshi Yoshii, Eita Nakamura, Katsutoshi Itoyama, Masataka Goto<br>
<strong>NMF vs PLCA: Infinite Factor Model and Infinite Mixture Model for Generative Process of Multiple-Pitch Sounds</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 21, pp. 1-10, 2016. [<a href="/articles/Yoshii_etal_NMFvsPLCA_SIGMUS112.pdf">PDF</a>]

<li>Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Hierarchical Bayesian Music Language Model Based on Repetition and Modification of Note Patterns and Application to Rhythm Transcription</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2016-MUS-112, No. 22, pp. 1-6, 2016. [<a href="/articles/Nakamura_etal_RhythmTranscription_SIGMUS112.pdf">PDF</a>]

<li>Eita Nakamura, Masatoshi Hamanaka, Keiji Hirata, Kazuyoshi Yoshii<br>
<strong>Tree-Structured Probabilistic Model of Melodic Musical Notes Based on GTTM</strong> (in Japanese)<br>
<em>30th Annual Meeting of the Japanese Society for Artificial Intelligence</em>, 3G4-OS-15b-4, pp. 1-3, 2016. [<a href="https://kaigi.org/jsai/webprogram/2016/pdf/584.pdf">Proceeding</a>]

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Multi-Channel Sound Source Localization and Separation Based on NMF-LDA Considering Low-Rankness and Sparseness of Source Spectrograms</strong> (in Japanese)<br>
<em>75th National Convention of Information Processing Society of Japan (IPSJ)</em>, 2016. <font color="#ff0080">(Student Award)</font> [<a href="/articles/板倉他_マルチチャネル音源定位と音源分離.pdf">PDF</a>]

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Pitch Estimation for Music Audio Signals Based on a Hierarchical Bayesian Model of Chords and Spectrograms</strong> (in Japanese)<br>
<em>75th National Convention of Information Processing Society of Japan (IPSJ)</em>, 2016. <font color="#ff0080">(Student Award)</font> [<a href="/articles/尾島他_階層ベイズモデルに基づく音楽音響信号の音高推定.pdf">PDF</a>]

<li>Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong>Automatic Note Estimation for Vocal F0s based on a Beat-Semi-Synchronous Hidden Markov Model</strong> (in Japanese)<br>
<em>75th National Convention of Information Processing Society of Japan (IPSJ)</em>, 2016. [<a href="/articles/錦見他_歌声音高奇跡に対する音符推定.pdf">PDF</a>]

<li>Eita Nakamura, Philippe Cuvillier, Arshia Cont, Nobutaka Ono, Shigeki Sagayama, Kenji Watanabe<br>
<strong>Score Following of Polyphonic MIDI Performances with Ornaments Based on a Hierarchical Probabilistic Model</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2015-MUS-108, No. 16, pp. 1-7, 2015. [<a href="https://ipsj.ixsq.nii.ac.jp/ej/index.php?active_action=repository_view_main_item_detail&page_id=13&block_id=8&item_id=144793&item_no=1">Proceeding</a>]

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama<br>
<strong>Rhythm Transcription of Polyphonic Music Using Merged-Output Hidden Markov Model</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2014-MUS-104, No. 8, pp. 1-7, 2014. [<a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=102548&item_no=1&page_id=13&block_id=8">Proceeding</a>]

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama<br>
<strong>Piano Reduction from Ensemble Scores Based on Piano Fingering Model for Both Hands</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2013-MUS-101, No. 14, pp. 1-12, 2013. <font color="#ff0080">(IPSJ Yamashita Research Award)</font> [<a href="https://ipsj.ixsq.nii.ac.jp/ej/index.php?active_action=repository_view_main_item_detail&page_id=13&block_id=8&item_id=96804&item_no=1">Proceeding</a>]

<li>Eita Nakamura, Yasuyuki Saito, Shigeki Sagayama<br>
<strong>Merged-Output Hidden Markov Model and Its Applications in Score Following and Hand Separation of Polyphonic Keyboard Music</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2013-EC-27, No. 15, pp. 1-6, 2013. [<a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=91191&item_no=1&page_id=13&block_id=8">Proceeding</a>]

<li>Naoya Ito, Satoru Fukayama, Eita Nakamura, Daisuke Saito, Shigeki Sagayama<br>
<strong>Automatic Music Performance Rendering Using Tempo Curve Generation Based on Music Structure</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2013-EC-27, No. 23, pp. 1-6, 2013. [<a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=91199&item_no=1&page_id=13&block_id=8">Proceeding</a>]

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong>Fast Score Following for Acoustic Signal of Musical Performance with Repeats and Skips</strong> (in Japanese)<br>
<em>Proc. 75th National Convention of Information Processing Society of Japan (IPSJ)</em>, Vol. 2013, No. 1, pp. 283-284, 2013. <font color="#ff0080">(Student Award)</font> [<a href="https://ipsj.ixsq.nii.ac.jp/ej/index.php?active_action=repository_view_main_item_detail&page_id=13&block_id=8&item_id=111314&item_no=1">Proceeding</a>]

<li>Tomohiko Nakamura, Yuu Mizuno, Kosuke Suzuki, Eita Nakamura, Yusuke Higuchi, Satoru Fukayama, Shigeki Sagayama<br>
<strong>Automatic Accompaniment Robust to Errors and Repetitions in Acoustic Musical Performances</strong> (in Japanese)<br>
<em>2012 Autumn Meeting of the Acoustical Society of Japan (ASJ)</em>, 2012.

<li>Eita Nakamura, Ryuichi Yamamoto, Yasuyuki Saito, Shinji Sako, Shigeki Sagayama,<br>
<strong>Modeling Ornaments for Polyphonic MIDI Score Following and Its Application to Automatic Accompaniment</strong> (in Japanese)<br>
<em>2012 Autumn Meeting of the Acoustical Society of Japan (ASJ)</em>, 2012.

<li>Eita Nakamura, Ryuichi Yamamoto, Shinji Sako, Yasuyuki Saito, Shigeki Sagayama<br>
<strong>Modeling Performance Indeterminacies for Polyphonic MIDI Score Following and Its Application to Automatic Accompaniment</strong> (in Japanese)<br>
<em>Technical Report IPSJ Special Interest Group on Music and Computer (SIGMUS)</em>, Vol. 2012-MUS-96, No. 14, pp. 1-6, 2012.

<li>Eita Nakamura<br>
<strong>SUSY Model Discrimination at an Early Stage of LHC</strong> (in Japanese)<br>
<em>Soryuushiron Kenkyu, 119(3), C47</em>, 2011.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong>Strongly Interacting Gauge Mediation at the LHC</strong><br>
<em>18th International Conference on Supersymmetry and Unification of Fundamental Interactions (SUSY10)</em>, 2010.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu Yanagida<br>
<strong>Low-Scale Gauge Mediation and Composite Messenger Dark Matter</strong> (in Japanese)<br>
<em>The 65th Annual Meeting of the Physical Society of Japan</em>, 2010.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong>Low-Scale Gauge Mediation and Composite Messenger Dark Matter</strong><br>
<em>17th International Conference on Supersymmetry and Unification of Fundamental Interactions (SUSY09)</em>, 2009.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu Yanagida<br>
<strong>Strongly Interacting Gauge Mediation Model at the LHC</strong> (in Japanese)<br>
<em>The 2008 Autumn Meeting of the Physical Society of Japan</em>, 2008.

        </ol>

        <h3><font color="#990000">Seminar Talks</font></h3>

        <ol class="pub" reversed>

<li><strong>Statistical Performance Model with Explicit Voice Structure and Symbolic Music Alignment</strong><br>
Talk at the Johannes Kepler University (hosted by Dr <a href="http://www.cp.jku.at/people/arzt/"><font color="#941651">Andreas Arzt</font></a> and Dr <a href="http://www.cp.jku.at/people/widmer/"><font color="#941651">Gerhard Widmer</font></a>), Linz, 6/Sep/2017.

<li><strong>Statistical Models of Musical Rhythm and Application to MIDI Transcription</strong><br>
Talk at the Utrecht University (hosted by Dr <a href="http://www.staff.science.uu.nl/~fleis102/"><font color="#941651">Anja Volk</font></a>), Utrecht, 4/Sep/2017.

<li><strong>Symbolic Music Transcription Using Statistical Music Language Models</strong><br>
Talk at the International Audio Laboratories Erlangen, Friedrich-Alexander University Erlangen-Nuremberg (hosted by Dr <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller"><font color="#941651">Meinard Müller</font></a>), Erlangen, 24/July/2017.

<li><strong>Bayesian Learning for Modelling Repeated and Modified Musical Note Patterns</strong><br>
MusICA Seminar at the University of Edinburgh (hosted by Mr <a href="http://homepages.inf.ed.ac.uk/s1331854/home.html"><font color="#941651">Andrew McLeod</font></a> and Dr <a href="http://homepages.inf.ed.ac.uk/steedman/"><font color="#941651">Mark Steedman</font></a>), Edinburgh, 21/June/2017.

<li><strong>Recent Developments in Statistical Modelling Techniques for Symbolic Music Processing</strong><br>
C4DM Seminar at the Centre for Digital Music at Queen Mary University of London, London, 10/May/2017.

<li><strong>Recent Developments of Statistical Generative Models for Musical Note Sequences</strong><br>
Invited Talk in <em>Workshop on Music Generation using Statistical Models</em> at University of the Basque Country (UPV/EHU) (hosted by Dr <a href="http://www.ehu.eus/cs-ikerbasque/conklin/"><font color="#941651">Darrell Conklin</font></a>), San Sebastian, 28/Jan/2017.

<li><strong>Rhythm Transcription of Piano Performances Based on Hierarchical Bayesian Modelling of Repetition and Modification of Musical Note Patterns</strong><br>
Invited Seminar at Universitat Pompeu Fabra (UPF), Barcelona, 15/Nov/2016.

<li><strong>Stochastic Modeling of Arbitrary Repeats and Skips in Music Performances and Score Following</strong><br>
Invited Seminar at Institut de Recherche et Coordination Acoustique/Musique (IRCAM), Paris, 16/Jan/2014.

        </ol>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Maintained by Eita Nakamura　　　　(Last updated: Apr 2019)</p>
        <h4><a href="http://eita-nakamura.github.io">Main page</a></h4>
      </footer>
    </div>

  </body>
</html>
