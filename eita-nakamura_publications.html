<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Eita-nakamura.GitHub.io : ">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Publications</title>

   <style>
      ul.pub {line-height: 20px;}
      ul.pub li {margin-bottom: 10px;}
      ol.pub {line-height: 20px;}
      ol.pub li {margin-bottom: 10px;}
    </style>

    <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-80849161-1', 'auto');
    ga('send', 'pageview');

    </script>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">Publications and Talks | 発表文献　 <a href="https://eita-nakamura.github.io"><font size="5" color="wheat">To main page</font></a> <font size="5" color="wheat">|</font> <a href="https://eita-nakamura.github.io/index-ja.html"><font size="5" color="wheat">メインページへ</font></a></h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <div align="center">
        <h5><a href="#Journal">Journal Papers | 雑誌論文</a></h5>
        <h5><a href="#ConferencePaper">Conference Papers (Refereed) | 会議論文 (査読あり)</a></h5>
        <h5><a href="#ConferenceTalks">Conference Talks (Unrefereed) | 学会発表 (査読なし)</a></h5>
        <h5><a href="#Seminar">Seminar Talks | 招待講演</a></h5>
        </div>

        <br>

        <h3 id="Journal"><font color="#990000">Journal Papers | 雑誌論文</font></h3>
        <ol class="pub" reversed>

<li>Rajsuryan Singh, Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/2205.13923.pdf" target="_blank"><font color="#222222">Dynamic cluster structure and predictive modelling of music creation style distributions</font></a></strong> <a href="https://arxiv.org/pdf/2205.13923.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<a href="https://arxiv.org/abs/2205.13923" target="_blank"><font color="#808080">[arXiv:2205.13923]</font></a>

<li>Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/2102.01465.pdf" target="_blank"><font color="#222222">Conjugate Distribution Laws in Cultural Evolution via Statistical Learning</font></a></strong> <a href="https://arxiv.org/pdf/2102.01465.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1103/PhysRevE.104.034309" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physical Review E</em>, Vol. 104, 034309, 2021. <a href="https://arxiv.org/abs/2102.01465" target="_blank"><font color="#808080">[arXiv:2102.01465]</font></a>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1908.06969.pdf" target="_blank"><font color="#222222">Musical Rhythm Transcription Based on Bayesian Piece-Specific Score Models Capturing Repetitions</font></a></strong> <a href="https://arxiv.org/pdf/1908.06969.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1016/j.ins.2021.04.100" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://bayesianscoremodel.github.io/" target="_blank"><button class="MyBtn GreenBtn">Web page</button></a><br>
<em>Information Sciences</em>, Vol. 572, pp. 482-500, 2021. <a href="https://arxiv.org/abs/1908.06969" target="_blank"><font color="#808080">[arXiv:1908.06969]</font></a>

<li>Kentaro Shibata, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/2008.12710.pdf" target="_blank"><font color="#222222">Non-Local Musical Statistics as Guides for Audio-to-Score Piano Transcription</font></a></strong> <a href="https://arxiv.org/pdf/2008.12710.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1016/j.ins.2021.03.014" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://audio2score.github.io/" target="_blank"><button class="MyBtn PinkBtn">Demo</button></a><br>
<em>Information Sciences</em>, Vol. 566, pp. 262-280, 2021. <a href="https://arxiv.org/abs/2008.12710" target="_blank"><font color="#808080">[arXiv:2008.12710]</font></a>

<li>Ryo Nishikimi, Eita Nakamura, Masataka Goto, Kazuyoshi Yoshii<br>
<strong><a href="https://www.doi.org/10.1017/ATSIP.2021.4" target="_blank"><font color="#222222">Audio-to-Score Singing Transcription Based on a CRNN-HSMM Hybrid Model</font></a></strong> <a href="https://www.doi.org/10.1017/ATSIP.2021.4" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="http://sap.ist.i.kyoto-u.ac.jp/members/nishikimi/demo/apsipa-tsip-2020/" target="_blank"><button class="MyBtn PinkBtn">Demo</button></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 10, e7, pp. 1-13 2021.

<li>Ryo Nishikimi, Eita Nakamura, Masataka Goto, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_BayesianSingingTranscription_2020.pdf" target="_blank"><font color="#222222">Bayesian Singing Transcription Based on a Hierarchical Generative Model of Keys, Musical Notes, and F0 Trajectories</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_BayesianSingingTranscription_2020.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="DOI: 10.1109/TASLP.2020.2996095" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 28, pp. 1678-1691, 2020.

<li>Hiroaki Tsushima, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Tsushima_etal_BayesianMelodyHarmonization_2020.pdf" target="_blank"><font color="#222222">Bayesian Melody Harmonization Based on a Tree-Structured Generative Model of Chord Sequences and Melodies</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Tsushima_etal_BayesianMelodyHarmonization_2020.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://ieeexplore.ieee.org/document/9098035" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 28, pp. 1644-1655, 2020.

<li>Go Shibata, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/柴田ら_音楽構造解析_2020.pdf" target="_blank"><font color="#222222">Statistical Method for Music Structure Analysis Based on a Hierarchical HSMM</font></a></strong> (in Japanese)<br>
<em>Journal of Information Processing Society of Japan</em>, Vol. 61, No. 4, pp. 757-767, 2020.<br>
柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/柴田ら_音楽構造解析_2020.pdf" target="_blank"><font color="#222222">同質性・反復性・規則性を考慮した階層隠れセミマルコフモデルに基づく統計的音楽構造解析</font></a></strong> <a href="https://eita-nakamura.github.io/articles/柴田ら_音楽構造解析_2020.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.20729/00204224" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>情報処理学会論文誌</em>, Vol. 61, No. 4, pp. 757-767, 2020.

<li>Eita Nakamura, Yasuyuki Saito, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><font color="#222222">Statistical Learning and Estimation of Piano Fingering</font></a></strong> <a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1016/j.ins.2019.12.068" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://statpianofingering.github.io/demo.html" target="_blank"><button class="MyBtn GreenBtn">Web page</button></a><br>
<em>Information Sciences</em>, Vol. 517, pp. 68-85, 2020. <a href="https://arxiv.org/abs/1904.10237" target="_blank"><font color="#808080">[arXiv:1904.10237]</font></a>

<li>Eita Nakamura, Kunihiko Kaneko<br>
<strong><a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><font color="#222222">Statistical Evolutionary Laws in Music Styles</font></a></strong> <a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.nature.com/articles/s41598-019-52380-6" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Scientific Reports</em>, Vol. 9, No. 15993, pp. 1-11, 2019. <a href="https://arxiv.org/abs/1809.05832" target="_blank"><font color="#808080">[arXiv:1809.05832]</font></a>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><font color="#222222">Statistical Piano Reduction Controlling Performance Difficulty</font></a></strong> <a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1017/ATSIP.2018.18" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://pianoarrangement.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt="Demo"></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 7, No. e13, pp. 1–12, 2018. <a href="https://arxiv.org/abs/1808.05006" target="_blank"><font color="#808080">[arXiv:1808.05006]</font> <a href="./citations/2018PianoReduction.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3DBA1E441E9EACB1DE3EF730D92B84C3/S2048770318000173a.pdf/chordaware_automatic_music_transcription_based_on_hierarchical_bayesian_integration_of_acoustic_and_language_models.pdf" target="_blank"><font color="#222222">Chord-Aware Automatic Music Transcription Based on Hierarchical Bayesian Integration of Acoustic and Language Models</font></a></strong> <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3DBA1E441E9EACB1DE3EF730D92B84C3/S2048770318000173a.pdf/chordaware_automatic_music_transcription_based_on_hierarchical_bayesian_integration_of_acoustic_and_language_models.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1017/ATSIP.2018.17" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 7, No. e14, pp. 1–14, 2018. <a href="./citations/2018MultipitchEstimationWithLanguageModel.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><font color="#222222">Generative Statistical Models with Self-Emergent Grammar of Chord Sequences</font></a></strong> <a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.tandfonline.com/doi/abs/10.1080/09298215.2018.1447584?journalCode=nnmr20" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 47, No. 3, pp. 226–248, 2018. <a href="https://arxiv.org/abs/1708.02255" target="_blank"><font color="#808080">[arXiv:1708.02255]</font> <a href="./citations/2018ChordModel.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><font color="#222222">Bayesian Multichannel Audio Source Separation Based on Integrated Source and Spatial Models</font></a></strong> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2789320" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 26, No. 4, pp. 1–16, 2018. <a href="./citations/2018BayesianMNMF.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><font color="#222222">Note Value Recognition for Piano Transcription Using Markov Random Fields</font></a></strong> <a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2722103" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://anonymous574868.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 9, pp. 1846–1858, 2017. <a href="https://arxiv.org/abs/1703.08144" target="_blank"><font color="#808080">[arXiv:1703.08144]</font></a> <a href="./citations/2017NoteValueRecognition.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices</font></a></strong> <a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2662479" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://anonymous4721029.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 4, pp. 794-806, 2017. <a href="https://arxiv.org/abs/1701.08343" target="_blank"><font color="#808080">[arXiv:1701.08343]</font></a> <a href="./citations/2017PolyphonicRhythmTranscription.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Misato Ohkita, Yoshiaki Bando, Yukara Ikemiya, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Ohkita_etal_DancingRobot_2017.pdf" target="_blank"><font color="#222222">Audio-Visual Beat Tracking Based on a State-Space Model for a Robot Dancer Performing with a Human Dancer</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Ohkita_etal_DancingRobot_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.fujipress.jp/jrm/rb/robot002900010125/" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of Robotics and Mechatronics</em>, Vol. 29, No. 1, pp. 125-136, 2017. <a href="./citations/2017DancingRobot.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><font color="#222222">Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips</font></a></strong> <a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://dx.doi.org/10.1109/TASLP.2015.2507862" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 24, No. 2, pp. 329-339, 2016. <a href="https://arxiv.org/abs/1512.07748" target="_blank"><font color="#808080">[arXiv:1512.07748]</font></a> <a href="./citations/2016AudioScofo.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama, Kenji Watanabe<br>
<strong><a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><font color="#222222">A Stochastic Temporal Model of Polyphonic MIDI Performance with Ornaments</font></a></strong> <a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.tandfonline.com/doi/full/10.1080/09298215.2015.1078819" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 44, No. 4, pp. 287-304, 2015. <a href="https://arxiv.org/abs/1404.2314" target="_blank"><font color="#808080">[arXiv:1404.2314]</font></a> <a href="./citations/2014OrnamentModel.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Tomohiko Nakamura, Yasuyuki Saito, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1404.2313v1.pdf" target="_blank"><font color="#222222">Outer-Product Hidden Markov Model and Polyphonic MIDI Score Following</font></a></strong> <a href="https://arxiv.org/pdf/1404.2313v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.tandfonline.com/doi/abs/10.1080/09298215.2014.884145#.VStjU6aR1lJ" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 43, No. 2, pp. 183-201, 2014. <a href="https://arxiv.org/abs/1404.2313" target="_blank"><font color="#808080">[arXiv:1404.2313]</font></a> <a href="./citations/2014OuterProductHMM.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Haruto Takeda, Ryuichi Yamamoto, Yasuyuki Saito, Shinji Sako, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><font color="#222222">Score Following Handling Performances with Arbitrary Repeats and Skips and Automatic Accompaniment</font></a></strong> (in Japanese) <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=91580&item_no=1&page_id=13&block_id=8" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of Information Processing Society of Japan</em>, Vol. 54, No. 4, pp. 1338-1349, 2013.<br>
中村栄太, 武田晴登, 山本龍一, 齋藤康之, 酒向慎司, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><font color="#222222">任意箇所への弾き直し・弾き飛ばしを含む演奏に追従可能な楽譜追跡と自動伴奏</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ScoreFollowing_IPSJ2013.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=91580&item_no=1&page_id=13&block_id=8" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>情報処理学会論文誌</em>, Vol. 54, No. 4, pp. 1338-1349, 2013.

<li>Shoji Asai, Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/1202.3584v2.pdf" target="_blank"><font color="#222222">Discriminating Minimal SUGRA and Minimal Gauge Mediation Models at the Early LHC</font></a></strong> <a href="https://arxiv.org/pdf/1202.3584v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://link.springer.com/article/10.1007%2FJHEP04(2012)003" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1204, No. 003, pp. 1-22, 2012. <a href="https://arxiv.org/abs/1202.3584" target="_blank"><font color="#808080">[arXiv:1202.3584]</font></a>

<li>Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/1010.5995v3.pdf" target="_blank"><font color="#222222">Discovery Potential for Low-Scale Gauge Mediation at Early LHC</font></a></strong> <a href="https://arxiv.org/pdf/1010.5995v3.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://link.springer.com/article/10.1007%2FJHEP03(2011)115" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1103, No. 115, pp. 1-15, 2011. <a href="https://arxiv.org/abs/1010.5995" target="_blank"><font color="#808080">[arXiv:1010.5995]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0912.1683v1.pdf" target="_blank"><font color="#222222">Low-Scale Gauge Mediation and Composite Messenger Dark Matter</font></a></strong> <a href="https://arxiv.org/pdf/0912.1683v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://link.springer.com/article/10.1007%2FJHEP04(2010)119" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 1004, No. 119, pp. 1-14, 2010. <a href="https://arxiv.org/abs/0912.1683" target="_blank"><font color="#808080">[arXiv:0912.1683]</font></a>

<li>Koichi Hamaguchi, Kouhei Nakaji, Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/0905.1574v1.pdf" target="_blank"><font color="#222222">Inverse Problem of Cosmic-Ray Electron/Positron from Dark Matter</font></a></strong> <a href="https://arxiv.org/pdf/0905.1574v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.sciencedirect.com/science/article/pii/S0370269309010065" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 680, pp. 172-178, 2009. <a href="https://arxiv.org/abs/0905.1574" target="_blank"><font color="#808080">[arXiv:0905.1574]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><font color="#222222">Decaying Dark Matter Baryons in a Composite Messenger Model</font></a></strong> <a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.sciencedirect.com/science/article/pii/S0370269309003013" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 674, pp. 299-302, 2009. <a href="https://arxiv.org/abs/0811.0737" target="_blank"><font color="#808080">[arXiv:0811.0737]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai<br>
<strong><a href="https://arxiv.org/pdf/0805.2502v1.pdf" target="_blank"><font color="#222222">A Measurement of Neutralino Mass at the LHC in Light Gravitino Scenarios</font></a></strong> <a href="https://arxiv.org/pdf/0805.2502v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.sciencedirect.com/science/article/pii/S037026930800782X" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 666, pp. 57-61, 2008. <a href="https://arxiv.org/abs/0805.2502" target="_blank"><font color="#808080">[arXiv:0805.2502]</font></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0804.3296v2.pdf" target="_blank"><font color="#222222">Strongly Interacting Gauge Mediation at the LHC</font></a></strong> <a href="https://arxiv.org/pdf/0804.3296v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://iopscience.iop.org/1126-6708/2008/07/107" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of High Energy Physics</em>, Vol. 0807, No. 107, pp. 1-11, 2008. <a href="https://arxiv.org/abs/0804.3296" target="_blank"><font color="#808080">[arXiv:0804.3296]</font></a>

        </ol>

        <h3 id="ConferencePaper"><font color="#990000">Conference Papers (Refereed) | 会議論文 (査読あり)</font></h3>

        <ol class="pub" reversed>

<li>Florian Thalmann, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Tracking the evolution of a band's performances over decades</font></strong><br>
<em>Proc. 23rd International Society for Music Information Retrieval Conference (ISMIR)</em>, to be presented, December 2022.

<li>Tengyu Deng, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><font color="#222222">End-to-end lyrics transcription informed by pitch and onset estimation</font></strong><br>
<em>Proc. 23rd International Society for Music Information Retrieval Conference (ISMIR)</em>, to be presented, December 2022.

<li>Pedro Ramoneda, Dasaem Jeong, Eita Nakamura, Xavier Serra, Marius Miron<br>
<strong><font color="#222222">Automatic piano fingering from partially annotated scores using autoregressive neural networks</font></strong><br>
<em>Proc. 30th ACM International Conference on Multimedia (ACMMM)</em>, to be presented, October 2022.

<li>Yuki Hiramatsu, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Hiramatsu_etal_PianoTranscription_ISMIR2021.pdf" target="_blank"><font color="#222222">Joint Estimation of Note Values and Voices for Audio-to-Score Piano Transcription</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Hiramatsu_etal_PianoTranscription_ISMIR2021.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 22nd International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 278-284, November 2021.

<li>Yuki Hiramatsu, Go Shibata, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Hiramatsu_etal_TranscriptionCorrection_ICASSP2021.pdf" target="_blank"><font color="#222222">Statistical Correction of Transcribed Melody Notes Based on Probabilistic Integration of a Music Language Model and a Transcription Error Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Hiramatsu_etal_TranscriptionCorrection_ICASSP2021.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 46th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 256-260, June 2021.

<li>Yasuyuki Saito, Yasui Sakai, Yuu Igarashi, Suguru Agata, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://ieeexplore.ieee.org/document/9081220" target="_blank"><font color="#222222">Music Recreation in Nursing Home using Automatic Music Accompaniment System and Score of VLN</font></a></strong><br>
<em>Proc. 2nd IEEE Global Conference on Life Sciences and Technologies (LifeTech)</em>, pp. 127-131, March 2020.

<li>Go Shibata, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Shibata_etal_StatisticalMusicStructureAnalysis_2019.pdf" target="_blank"><font color="#222222">Statistical Music Structure Analysis Based on a Homogeneity- and Repetitiveness-Aware Hierarchical Hidden Semi-Markov Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Shibata_etal_StatisticalMusicStructureAnalysis_2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 20th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 268-275, November 2019.

<li>Ryo Nishikimi, Eita Nakamura, Masataka Goto, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_EndToEndMelodyNoteTranscription_WASPAA2019.pdf" target="_blank"><font color="#222222">End-to-End Melody Note Transcription Based on a Beat-Synchronous Attention Mechanism</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_EndToEndMelodyNoteTranscription_WASPAA2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em>, pp. 26-30, October 2019.

<li>Tristan Carsault, Andrew McLeod, Philippe Esling, Jérôme Nika, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://ieeexplore.ieee.org/document/8918813" target="_blank"><font color="#222222">Multi-Step Chord Sequence Prediction Based on Aggregated Multi-Scale Encoder-Decoder Networks</font></a></strong><br>
<em>Proc. 29th IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em>, pp. 1-6, October 2019.

<li>Yui Uehara, Eita Nakamura, Satoshi Tojo<br>
<strong><a href="https://eita-nakamura.github.io/articles/Uehara_etal_ChordFunctionIdentificationWithModulationDetectionBasedOnHMM_2019.pdf" target="_blank"><font color="#222222">Chord Function Identification with Modulation Detection Based on HMM</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Uehara_etal_ChordFunctionIdentificationWithModulationDetectionBasedOnHMM_2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 14th International Symposium on Computer Music Multidisciplinary Research (CMMR)</em>, pp. 59-70, October 2019.

<li>Eita Nakamura, Kentaro Shibata, Ryo Nishikimi, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_StatisticalMelodyArrangement_ICASSP2019.pdf" target="_blank"><font color="#222222">Unsupervised Melody Style Conversion</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_StatisticalMelodyArrangement_ICASSP2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a> <a href="https://melodyarrangement.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt="Demo"></a> <a href="https://www.youtube.com/watch?v=82K1GPnaSfM" target="_blank"><img src="https://eita-nakamura.github.io/images/video.png" height="18px" alt="Video"></a><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 196-200, May 2019.

<li>Kentaro Shibata, Ryo Nishikimi, Satoru Fukayama, Masataka Goto, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Shibata_etal_GuitarTranscription_ICASSP2019.pdf" target="_blank"><font color="#222222">Joint Transcription of Lead, Bass, and Rhythm Guitars Based on a Factorial Hidden Semi-Markov Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Shibata_etal_GuitarTranscription_ICASSP2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 236-240, May 2019.

<li>Andrew McLeod, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://ieeexplore.ieee.org/document/8683808" target="_blank"><font color="#222222">Improved Metrical Alignment of MIDI Performance Based on a Repetition-Aware Online-Adapted Grammar</font></a></strong><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 186-190, May 2019.

<li>Ryo Nishikimi, Eita Nakamura, Satoru Fukayama, Masataka Goto, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_SingingTranscriptionUsingAttention_ICASSP2019.pdf" target="_blank"><font color="#222222">Automatic Singing Transcription Based on Encoder-Decoder Recurrent Neural Networks with a Weakly-Supervised Attention Mechanism</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_SingingTranscriptionUsingAttention_ICASSP2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 161-165, May 2019.

<li>Shun Ueda, Kentaro Shibata, Yusuke Wada, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Ueda_etal_DrumTranscription_ICASSP2019.pdf" target="_blank"><font color="#222222">Bayesian Drum Transcription Based on Nonnegative Matrix Factor Decomposition with a Deep Score Prior</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Ueda_etal_DrumTranscription_ICASSP2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 456-460, May 2019.

<li>Eita Nakamura, Ryo Nishikimi, Simon Dixon, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><font color="#222222">Probabilistic Sequential Patterns for Singing Transcription</font></a></strong> <a href="https://eita-nakamura.github.io/articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, pp. 1905-1912, November 2018.

<li>Yusuke Wada, Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Wada_etal_SingingF0GenerationByWaveNet_2018.pdf" target="_blank"><font color="#222222">Sequential Generation of Singing F0 Contours from Musical Note Sequences Based on WaveNet</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Wada_etal_SingingF0GenerationByWaveNet_2018.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, pp. 983-989, November 2018.

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Tsushima_etal_InteractiveArrangement_ISMIR2018.pdf" target="_blank"><font color="#222222">Interactive Arrangement of Chords and Melodies Based on a Tree-Structured Generative Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Tsushima_etal_InteractiveArrangement_ISMIR2018.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 19th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 145-151, September 2018.

<li>Kazuyoshi Yoshii, Koichi Kitamura, Yoshiaki Bando, Eita Nakamura, Tatsuya Kawahara<br>
<strong><font color="#222222">Independent Low-Rank Tensor Analysis for Audio Source Separation</font></strong><br>
<em>Proc. 26th European Signal Processing Conference (EUSIPCO)</em>, September 2018.

<li>Yasuyuki Saito, Yasuji Sakai, Yuu Igarashi, Eita Nakamura, Suguru Agata, Shigeki Sagayama<br>
<strong><font color="#222222">Automatic Music Accompaniment Technology Applied to Recreational Singing Activities at Long-Term Health-Care Facilities</font></strong><br>
<em>Proc. 3rd Computer Simulation of Musical Creativity Conference (CSMC)</em>, August 2018.

<li>Mitsuyo Hashida, Eita Nakamura, Haruhiro Katayose<br>
<strong><a href="https://eita-nakamura.github.io/articles/Hashida_etal_CrestMusePEDB2ndEd_SMC2018.pdf" target="_blank"><font color="#222222">CrestMusePEDB 2nd Edition: Music Performance Database with Phrase Information</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Hashida_etal_CrestMusePEDB2ndEd_SMC2018.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Sound and Music Computing Conference (SMC)</em>, July 2018.

<li>Eita Nakamura, Emmanouil Benetos, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="https://eita-nakamura.github.io/articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><font color="#222222">Towards Complete Polyphonic Music Transcription: Integrating Multi-Pitch Detection and Rhythm Quantization</font></a></strong> <a href="https://eita-nakamura.github.io/articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 43rd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 101-105, April, 2018.

<li>Kazuyoshi Yoshii, Eita Nakamura, Katsutoshi Itoyama, Masataka Goto<br>
<strong><a href="https://eita-nakamura.github.io/articles/Yoshii_etal_InfiniteProbabilisticLatentComponentAnalysisForAudioSourceSeparation_2017.pdf" target="_blank"><font color="#222222">Infinite Probabilistic Latent Component Analysis For Audio Source Separation</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Yoshii_etal_InfiniteProbabilisticLatentComponentAnalysisForAudioSourceSeparation_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 18th IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em>, pp. 347-353, 2017. 

<li>Eita Nakamura, Kazuyoshi Yoshii, Haruhiro Katayose<br>
<strong><a href="https://eita-nakamura.github.io/articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><font color="#222222">Performance Error Detection and Post-Processing for Fast and Accurate Symbolic Music Alignment</font></a></strong> <a href="https://eita-nakamura.github.io/articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://midialignment.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 347-353, 2017.

<li>Ryo Nishikimi, Eita Nakamura, Masataka Goto, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_ScaleAndRhythmAwareMusicalNoteEstimationForVocalF0_ISMIR2017.pdf" target="_blank"><font color="#222222">Scale- and Rhythm-Aware Musical Note Estimation for Vocal F0 Trajectories Based on a Semi-Tatum-Synchronous Hierarchical Hidden Semi-Markov Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_ScaleAndRhythmAwareMusicalNoteEstimationForVocalF0_ISMIR2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="http://sap.ist.i.kyoto-u.ac.jp/members/nishikimi/demo/ismir2017/" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 376-382, 2017.

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Tsushima_etal_MelodyHarmonization_ISMIR2017.pdf" target="_blank"><font color="#222222">Function- and Rhythm-Aware Melody Harmonization Based on Tree-Structured Parsing and Split-Merge Sampling of Chord Sequences</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Tsushima_etal_MelodyHarmonization_ISMIR2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://anonym9329.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 502-508, 2017.

<li>Yusuke Wada, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Wada_etal_AdaptiveKaraokeSystem_SMC2017.pdf" target="_blank"><font color="#222222">An Adaptive Karaoke System that Plays Accompaniment Parts of Music Audio Signals Synchronously with Users' Singing Voices</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Wada_etal_AdaptiveKaraokeSystem_SMC2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="http://sap.ist.i.kyoto-u.ac.jp/members/wada/smc2017/index.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 14th Sound and Music Computing Conference (SMC)</em>, pp. 110-116, 2017.

<li>Mitsuyo Hashida, Eita Nakamura, Haruhiro Katayose<br>
<strong><a href="https://eita-nakamura.github.io/articles/Hashida_etal_ConstructingPEDB2ndEdition_SMC2017.pdf" target="_blank"><font color="#222222">Constructing PEDB 2nd Edition: A Music Performance Database with Phrase Information</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Hashida_etal_ConstructingPEDB2ndEdition_SMC2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 14th Sound and Music Computing Conference (SMC)</em>, pp. 359-364, 2017.

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong><a href="https://eita-nakamura.github.io/articles/Itakura_etal_BayesianMultichannelNMFForAudioSourceSeparation_ICASSP2017.pdf" target="_blank"><font color="#222222">Bayesian Multichannel Nonnegative Matrix Factorization for Audio Source Separation and Localization</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Itakura_etal_BayesianMultichannelNMFForAudioSourceSeparation_ICASSP2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://ieeexplore.ieee.org/document/7952216/" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 551-555, 2017.

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscriptionOfPolyphonicMIDIPerformances_SMC2016.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic MIDI Performances Based on a Merged-Output HMM for Multiple Voices</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscriptionOfPolyphonicMIDIPerformances_SMC2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://anonymous4721029.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 13th Sound and Music Computing Conference (SMC)</em>, pp. 338-343, 2016.

<li>Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><font color="#222222">Rhythm Transcription of MIDI Performances Based on Hierarchical Bayesian Modelling of Repetition and Modification of Musical Note Patterns</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 24th European Signal Processing Conference (EUSIPCO)</em>, pp. 1946-1950, 2016.

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Itakura_etal_AUnifiedBayesianModelForMultichannelSourceSeparation_EUSIPCO2016.pdf" target="_blank"><font color="#222222">A Unified Bayesian Model of Time-Frequency Clustering and Low-Rank Approximation for Multi-Channel Source Separation</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Itakura_etal_AUnifiedBayesianModelForMultichannelSourceSeparation_EUSIPCO2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 24th European Signal Processing Conference (EUSIPCO)</em>, pp. 2280-2284, 2016.

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Ojima_etal_AHierarchicalBayesianModelOfChordsPitchesAndSpectrograms_ISMIR2016.pdf" target="_blank"><font color="#222222">A Hierarchical Bayesian Model of Chords, Pitches, and Spectrograms for Multipitch Analysis</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Ojima_etal_AHierarchicalBayesianModelOfChordsPitchesAndSpectrograms_ISMIR2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 17th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 309-315, 2016. 

<li>Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_MusicalNoteEstimationForF0TrajectoriesOfSingingVoices_ISMIR2016.pdf" target="_blank"><font color="#222222">Musical Note Estimation for F0 Trajectories of Singing Voices Based on a Bayesian Semi-Beat-Synchronous HMM</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_MusicalNoteEstimationForF0TrajectoriesOfSingingVoices_ISMIR2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 17th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 461-467, 2016. 

<li>Yasuyuki Saito, Eita Nakamura, Riku Sato, Suguru Agata, Yuu Igarashi, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Saito_etal_ConversionFromStandardMIDIFilesToVerticalLineNationaScores_2016.pdf" target="_blank"><font color="#222222">Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Saito_etal_ConversionFromStandardMIDIFilesToVerticalLineNationaScores_2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 2nd International Conference on Technologies for Music Notation and Representation (TENOR)</em>, pp. 200-211, 2016.

<li>Eita Nakamura, Masatoshi Hamanaka, Keiji Hirata, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_TreeStructuredProbabilisticModel_ICASSP2016.pdf" target="_blank"><font color="#222222">Tree-Structured Probabilistic Model of Monophonic Written Music Based on the Generative Theory of Tonal Music</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_TreeStructuredProbabilisticModel_ICASSP2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 276-280, 2016.

<li>Eita Nakamura, Philippe Cuvillier, Arshia Cont, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ARHSMMForScoreFollowing_ISMIR2015.pdf" target="_blank"><font color="#222222">Autoregressive Hidden Semi-Markov Model of Symbolic Music Performance for Score Following</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_ARHSMMForScoreFollowing_ISMIR2015.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://ismir2015.uma.es/articles/15_Paper.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 16th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 392-398, 2015.

<li>Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><font color="#222222">Automatic Piano Reduction from Ensemble Scores Based on Merged-Output Hidden Markov Model</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://quod.lib.umich.edu/i/icmc/bbp2372.2015.060/" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 41st International Computer Music Conference (ICMC)</em>, pp. 298-305, 2015.

<li>Eita Nakamura, Shinji Takaki<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><font color="#222222">Characteristics of Polyphonic Music Style and Markov Model of Pitch-Class Intervals</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-20603-5_10" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 5th Mathematics and Computation in Music (MCM)</em>, pp. 109-114, 2015.

<li>Riku Sato, Yasuyuki Saito, Suguru Agata, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Sato_etal_AutomaticGenerationOfMusicalScoreInVerticalLineNotationFromMIDIFile_2015.pdf" target="_blank"><font color="#222222">Automatic Generation of Musical Score in Vertical Line Notation from MIDI File</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Sato_etal_AutomaticGenerationOfMusicalScoreInVerticalLineNotationFromMIDIFile_2015.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 1st International Conference on Advanced Imaging (ICAI)</em>, T105-04, pp. 559-562, 2015.

<li>Haruka Jibiki, Toshikazu Shimizu, Yasuyuki Saito, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Jibiki_etal_AStudyOfAutomaticPageTurningOfMusicalScores_2015.pdf" target="_blank"><font color="#222222">A Study of Automatic Page Turning of Musical Scores by Detecting Player's Nods</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Jibiki_etal_AStudyOfAutomaticPageTurningOfMusicalScores_2015.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 1st International Conference on Advanced Imaging (ICAI)</em>, PB1-08, pp. 272-275, 2015.

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><font color="#222222">Merged-Output HMM for Piano Fingering of Both Hands</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.terasoft.com.tw/conf/ismir2014/proceedings/T096_251_Paper.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 15th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 531-536, 2014.

<li>Eita Nakamura, Yasuyuki Saito, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_MergedOutputHiddenMarkovModelForScoreFollowing_2014.pdf" target="_blank"><font color="#222222">Merged-Output Hidden Markov Model for Score Following of MIDI Performance with Ornaments, Desynchronized Voices, Repeats and Skips</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_MergedOutputHiddenMarkovModelForScoreFollowing_2014.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://hdl.handle.net/2027/spo.bbp2372.2014.182" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. Joint 40th International Computer Music Conference (ICMC) | 11th Sound and Music Computing Conference (SMC)</em>, pp. 1185-1192, 2014.

<li>Shigeki Sagayama, Tomohiko Nakamura, Eita Nakamura, Yasuyuki Saito, Hirokazu Kameoka, Nobutaka Ono<br>
<strong><a href="https://eita-nakamura.github.io/articles/Sagayama_etal_AutomaticMuiscAccompanimentAllowingErrorsAndArbitraryRepeatsAndJumps_2014.pdf" target="_blank"><font color="#222222">Automatic Music Accompaniment Allowing Errors and Arbitrary Repeats and Jumps</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Sagayama_etal_AutomaticMuiscAccompanimentAllowingErrorsAndArbitraryRepeatsAndJumps_2014.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://scitation.aip.org/content/asa/journal/poma/21/1/10.1121/1.4904932" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 167th Meeting of Acoustical Society of America (ASA)</em>, POMA Vol. 21 No. 035003, pp. 1-11, 2014. <font color="#ff0080">(Invited Talk)</font>

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_AcousticScoreFollowingToMusicalPerformanceWithErrorsAndArbitraryRepeatsAndSkips_2014.pdf" target="_blank"><font color="#222222">Acoustic Score Following to Musical Performance with Errors and Arbitrary Repeats and Skips for Automatic Accompaniment</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_AcousticScoreFollowingToMusicalPerformanceWithErrorsAndArbitraryRepeatsAndSkips_2014.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://smcnetwork.org/system/files/ACOUSTIC%20SCORE%20FOLLOWING%20TO%20MUSICAL%20PERFORMANCE%20WITH%20ERRORS%20AND%20ARBITRARY%20REPEATS%20AND%20SKIPS%20FOR%20AUTOMATIC%20ACCOMPANIMENT.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 10th Sound and Music Computing Conference (SMC)</em>, pp. 1185-1192, 2014.

        </ol>

        <h3 id="ConferenceTalks"><font color="#990000">Conference Talks (Unrefereed) | 学会発表 (査読なし)</font></h3>

        <ol class="pub" reversed>

<li>中村栄太, Rajsuryan Singh<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_作曲スタイル分布の分析と予測_2022.pdf" target="_blank"><font color="#222222">作曲スタイル分布の動的クラスター構造の分析と予測</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_作曲スタイル分布の分析と予測_2022.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第135回情報処理学会音楽情報科学研究報告</em>, Vol. 2022-MUS-135, No. 11, pp. 1–8, September 2022. <font color="#ff0080"></font>

<li>大山偉永, 中村栄太, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/大山ら_ビート・ダウンビート推定_2022.pdf" target="_blank"><font color="#222222">TCN-HSMMハイブリッドモデルに基づくビート・ダウンビート推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/大山ら_ビート・ダウンビート推定_2022.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第135回情報処理学会音楽情報科学研究報告</em>, Vol. 2022-MUS-135, No. 6, pp. 1–8, September 2022. <font color="#ff0080"></font> <font color="#ff0080">(学生奨励賞)</font>

<li>寺尾萌夢, 中村栄太, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/寺尾ら_ピアノ編曲_2022.pdf" target="_blank"><font color="#222222">バンド譜から無段階で難易度調整可能な深層ピアノ編曲</font></a></strong> <a href="https://eita-nakamura.github.io/articles/寺尾ら_ピアノ編曲_2022.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第135回情報処理学会音楽情報科学研究報告</em>, Vol. 2022-MUS-135, No. 3, pp. 1–7, September 2022. <font color="#ff0080"></font> <font color="#ff0080">(ベストプレゼンテーション賞)</font>

<li>加藤徳啓, 中村栄太, 峯恭子, 土江田織江, 山田昌尚<br>
<strong><a href="https://eita-nakamura.github.io/articles/加藤ら_ピアノ練習演奏の弾き間違い分析_2022.pdf" target="_blank"><font color="#222222">隠れマルコフモデルを用いたピアノ練習演奏の弾き間違い分析</font></a></strong> <a href="https://eita-nakamura.github.io/articles/加藤ら_ピアノ練習演奏の弾き間違い分析_2022.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第21回情報科学技術フォーラム（FIT2022）</em>, E-014, pp. 241-242, September 2022. <font color="#ff0080"></font> <font color="#ff0080">(FIT2022奨励賞)</font>

<li>齋藤康之, 中村栄太, 饗庭絵里子, 金子仁美<br>
<strong><a href="https://eita-nakamura.github.io/articles/齋藤ら_モデルによる運指補完_2022.pdf" target="_blank"><font color="#222222">モデルによる補完を用いたピアノ運指の効率的なラベル付けの検証</font></a></strong> <a href="https://eita-nakamura.github.io/articles/齋藤ら_モデルによる運指補完_2022.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第134回情報処理学会音楽情報科学研究報告</em>, Vol. 2022-MUS-134, No. 25, pp. 1–6, June 2022. <font color="#ff0080"></font>

<li>加藤徳啓, 谷口寛翔, 中村栄太, 峯恭子, 土江田織江, 山田昌尚<br>
<strong><font color="#222222">隠れマルコフモデルを用いたピアノ学習者の練習時間分析</font></strong><br>
<em>第84回情報処理学会全国大会</em>, 5T-02, March 2022. <font color="#ff0080"></font>

<li>中村栄太, 持橋大地, 齋藤康之<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_共役分布則_2021.pdf" target="_blank"><font color="#222222">統計学習を介する文化進化のモデルと音楽・文芸・絵画データにおける共役分布則</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_共役分布則_2021.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第132回情報処理学会音楽情報科学研究報告</em>, Vol. 2021-MUS-132, No. 16, pp. 1–10, September 2021. <font color="#ff0080">(ベストプレゼンテーション賞)</font>

<li>中村栄太, 金子仁美, 伊藤貴之, 金子邦彦<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_音楽進化実験_2021.pdf" target="_blank"><font color="#222222">自動作曲を用いた進化実験による音楽スタイルのクラスター形成過程の分析</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_音楽進化実験_2021.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第132回情報処理学会音楽情報科学研究報告</em>, Vol. 2021-MUS-132, No. 14, pp. 1–8, September 2021.

<li>平松祐紀, 柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>ピアノ採譜のための深層学習に基づく音価と声部の同時推定</strong><br>
<em>第83回情報処理学会全国大会</em>, 1P-01, March 2021. <font color="#ff0080">(学生奨励賞)</font>

<li>石塚崚斗, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>大局的構造に基づく正則化を用いた自己注意機構付き深層ドラム採譜</strong><br>
<em>第129回情報処理学会音楽情報科学研究報告</em>, Vol. 2020-MUS-129, No. 3, pp. 1–8, November 2020. <font color="#ff0080">(学生奨励賞)</font> 

<li>柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>LSTM-HSMMハイブリッドモデルに基づく音楽構造解析</strong><br>
<em>第128回情報処理学会音楽情報科学研究報告</em>, Vol. 2020-MUS-128, No. 10, pp. 1–8, August 2020. <font color="#ff0080">(ベストプレゼンテーション賞)</font> 

<li>石塚崚斗, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>事前学習済み言語モデルによる正則化を用いた深層ドラム採譜</strong><br>
<em>第128回情報処理学会音楽情報科学研究報告</em>, Vol. 2020-MUS-128, No. 8, pp. 1–7, August 2020.

<li>柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>階層隠れセミマルコフモデルと深層学習に基づく楽曲セクションの境界推定とラベル付け</strong><br>
<em>第82回情報処理学会全国大会</em>, 2S-08, pp. 343-344, March 2020. <font color="#ff0080">(学生奨励賞)</font>

<li>石塚崚斗, 上田瞬, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>深層音響・言語モデルの統合に基づくドラム採譜</strong><br>
<em>第82回情報処理学会全国大会</em>, 5S-05, pp. 369-370, March 2020. <font color="#ff0080">(学生奨励賞)</font>

<li>平松祐紀, 柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>音楽言語モデルと採譜誤りモデルに基づく歌声採譜結果の訂正</strong><br>
<em>第82回情報処理学会全国大会</em>, 5S-06, pp. 371-372, March 2020.

<li>柴田健太郎, 中村栄太, 錦見亮, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/柴田ら_ピアノ採譜_2019.pdf" target="_blank"><font color="#222222">深層多重音検出を用いた音響信号から楽譜へのピアノ採譜</font></a></strong> <a href="https://eita-nakamura.github.io/articles/柴田ら_ピアノ採譜_2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第125回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-125, No. 1, pp. 1–6, November 2019. <font color="#ff0080">(学生奨励賞)</font>

<li>呉益明, Tristan Carsault, 中村 栄太, 吉井 和佳<br>
<strong>音楽音響信号に対するラベル・テクスチャ分離型変分自己符号化器を用いた半教師ありコード推定</strong><br>
<em>第124回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-124, No. 5, pp. 1–6, August 2019. <font color="#ff0080">(ベストプレゼンテーション賞)</font> <a href="https://www.ipsj.or.jp/award/yamashita2020.html" target="_blank"><font color="#ff0080">(情報処理学会山下記念研究賞)</font></a>

<li>錦見亮, 中村栄太, 吉井和佳<br>
<strong>ビート同期注意機構に基づく歌声のリズム採譜</strong><br>
<em>第124回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-124, No. 8, pp. 1–6, August 2019.

<li>中村栄太, 齋藤康之, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_ピアノ運指推定と難易度_2019.pdf" target="_blank"><font color="#222222">ピアノ運指データを用いた統計学習手法による運指推定と演奏難易度の定式化</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_ピアノ運指推定と難易度_2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第124回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-124, No. 12, pp. 1–16, August 2019.

<li>中村栄太, 柴田健太郎, 錦見亮, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_教師なしスタイル変換によるメロディーの自動生成_2019.pdf" target="_blank"><font color="#222222">教師なしスタイル変換によるメロディーの自動生成</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_教師なしスタイル変換によるメロディーの自動生成_2019.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第124回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-124, No. 2, pp. 1–8, August 2019.

<li>中村栄太, 齋藤康之, 吉井和佳<br>
<strong>ピアノ運指データを用いた運指の個人性の解析</strong><br>
<em>第123回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-123, No. 42, pp. 1–6, June 2019.

<li>上田舜, 柴田健太郎, 和田雄介, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>深層ドラム譜事前分布に基づく畳み込み非負値行列因子分解を用いたドラム採譜</strong><br>
<em>第122回情報処理学会音楽情報科学研究報告</em>, Vol. 2019-MUS-122, No. 26, pp. 1–6, February 2019.

<li>柴田健太郎, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>Cycle-Consistencyに基づく音楽音響信号の自動採譜</strong><br>
<em>第81回情報処理学会全国大会</em>, 4T-08, pp. 1–2, March 2019. <font color="#ff0080">(学生奨励賞)</font>

<li>柴田剛, 錦見亮, 中村栄太, 吉井和佳<br>
<strong>階層隠れマルコフモデルに基づく音楽音響信号に対する構造解析</strong><br>
<em>第81回情報処理学会全国大会</em>, 4T-06, pp. 1–2, March 2019.

<li>柴田健太郎, 錦見亮, 深山覚, 後藤真孝, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong>階乗隠れセミマルコフモデルに基づく音楽音響信号に対するカバー譜生成</strong><br>
<em>第121回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-121, No. 16, pp. 1–8, November 2018. <a href="https://www.ipsj.or.jp/award/yamashita2019.html" target="_blank"><font color="#ff0080">(情報処理学会山下記念研究賞)</font></a>

<li>中村栄太, Emmanouil Benetos, 吉井和佳, Simon Dixon<br>
<strong>多重音検出とリズム量子化の統合による多声音楽の自動採譜</strong><br>
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 19, 2018. <font color="#ff0080">(ベストプレゼンテーション賞)</font>

<li>錦見亮, 中村栄太, 深山覚, 後藤真孝, 吉井和佳<br>
<strong>注意機構を用いたエンコーダ・デコーダモデルに基づく歌声の音符推定</strong><br>
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 7, 2018.

<li>和田雄介, 錦見亮, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong>WaveNetを用いた楽譜情報に基づく歌唱F0軌跡の生成</strong><br>
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 8, 2018.

<li>津島啓晃, 中村栄太, 吉井和佳<br>
<strong>コードとメロディの階層的生成モデルに基づくインタラクティブ作曲システム</strong><br>
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 14, 2018.

<li>吉井和佳, 北村昂一, 坂東宜昭, 中村栄太, 河原達也<br>
<strong>モノラル音響信号に対する音源分離のための独立低ランクテンソル分析</strong><br>
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 18, 2018.

<li>津島啓晃, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong>和音系列に対するPCFGのベイズ学習とSplit-Mergeサンプリングを用いたメロディへの和声付け</strong><br>
<em>第20回情報論的学習理論ワークショップ (IBIS2017)</em>, T1-14, 2017.

<li>錦見亮, 中村栄太, 後藤真孝, 糸山克寿, 吉井和佳<br>
<strong>調とリズムを考慮した階層隠れセミマルコフモデルに基づく歌声の自動採譜</strong><br>
<em>第20回情報論的学習理論ワークショップ (IBIS2017)</em>, T1-20, 2017.

<li>齋藤康之, 中村栄太, 嵯峨山茂樹<br>
<strong>自動伴奏システムEurydiceのシステムの改善</strong><br>
<em>第13回日本電子キーボード音楽学会全国大会</em>, 2017.

<li>和田雄介, 坂東宜昭, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong>楽曲中の歌声とユーザ歌唱のリアルタイムアラインメントに基づく伴奏追従型カラオケシステム</strong><br>
<em>第116回情報処理学会音楽情報科学研究報告</em>, Vol. 2017-MUS-116, No. 3, 2017.

<li>津島啓晃, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong>和音系列の統計的木構造解析とSplit-Mergeサンプリングに基づくメロディへの和声付け</strong><br>
<em>第116回情報処理学会音楽情報科学研究報告</em>, Vol. 2017-MUS-116, No. 14, 2017.

<li>錦見亮, 中村栄太, 後藤真孝, 糸山克寿, 吉井和佳<br>
<strong>調とリズムを考慮した階層隠れセミマルコフモデルに基づく歌声F0軌跡に対する音符推定</strong><br>
<em>第116回情報処理学会音楽情報科学研究報告</em>, Vol. 2017-MUS-116, No. 17, pp. 1–7, 2017. <font color="#ff0080">(学生奨励賞)</font> <a href="https://www.ipsj.or.jp/award/yamashita2018.html" target="_blank"><font color="#ff0080">(情報処理学会山下記念研究賞)</font></a>

<li>橋田光代, 兼口敦音, 中村栄太, 古屋晋一, 小川容子, 片寄晴弘<br>
<strong>ピアニストの演奏解釈を記述した演奏表情データベースの構築</strong><br>
<em>第116回情報処理学会音楽情報科学研究報告</em>, Vol. 2017-MUS-116, No. 23, 2017.

<li>錦見亮, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/錦見ら_歌声音符推定_2017.pdf" target="_blank"><font color="#222222">スケールと音高の過渡的変化を考慮したHSMMに基づく歌声F0軌跡に対する音符推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/錦見ら_歌声音符推定_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第79回情報処理学会全国大会</em>, 2017.

<li>津島啓晃, 吉井和佳, 糸山克寿, 中村栄太<br>
<strong><a href="https://eita-nakamura.github.io/articles/津島ら_和音構文解析と自動生成_2017.pdf" target="_blank"><font color="#222222">ベイズ文脈自由文法に基づく和音系列の教師なし構文解析と自動生成</font></a></strong> <a href="https://eita-nakamura.github.io/articles/津島ら_和音構文解析と自動生成_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第79回情報処理学会全国大会</em>, 2017. <font color="#ff0080">(学生奨励賞)</font>

<li>和田雄介, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/和田ら_スマートカラオケシステム_2017.pdf" target="_blank"><font color="#222222">市販音楽CDを用いたユーザ歌唱に伴奏音が自動追従するスマートカラオケシステム</font></a></strong> <a href="https://eita-nakamura.github.io/articles/和田ら_スマートカラオケシステム_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第79回情報処理学会全国大会</em>, 2017.

<li>福田翼, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/福田ら_楽譜簡略化と自動補完伴奏_2017.pdf" target="_blank"><font color="#222222">楽譜簡略化と自動補完伴奏によるピアノ演奏練習支援システム</font></a></strong> <a href="https://eita-nakamura.github.io/articles/福田ら_楽譜簡略化と自動補完伴奏_2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第114回情報処理学会音楽情報科学研究報告</em>, Vol. 2017-MUS-114, No. 21, pp. 1-4, 2017.

<li>地曳はるか, 齋藤康之, 中村栄太, 嵯峨山茂樹<br>
<strong>視線解析を併用した頷き動作による自動譜めくりシステム</strong><br>
<em>映像情報メディア学会 メディア工学研究会</em>, 2017.

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong>Comparative Evaluation of Rhythm Transcription Algorithms on Polyphonic Piano Datasets</strong><br>
<em>Digital Music Research Network Workshop 2016 (DMRN+11)</em>.

<li>尾島優太, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/尾島ら_多重音高推定_2016.pdf" target="_blank"><font color="#222222">音楽音響信号に対する多重音高推定と和音構造学習のための階層ベイズ音響・言語統合モデル</font></a></strong> <a href="https://eita-nakamura.github.io/articles/尾島ら_多重音高推定_2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第19回情報論的学習理論ワークショップ (IBIS2016)</em>, T2-23, 2016. <font color="#ff0080">(学生優秀プレゼンテーション賞)</font>

<li>錦見亮, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/錦見ら_歌声採譜のためのセグメンタルHMM_2016.pdf" target="_blank"><font color="#222222">歌声F0軌跡に対する自動採譜のための準ビート同期セグメンタルHMM</font></a></strong> <a href="https://eita-nakamura.github.io/articles/錦見ら_歌声採譜のためのセグメンタルHMM_2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第19回情報論的学習理論ワークショップ (IBIS2016)</em>, T2-24, 2016.

<li>板倉光佑, 坂東宜昭, 中村栄太, 糸山克寿, 吉井和佳, 河原達也<br>
<strong><a href="https://eita-nakamura.github.io/articles/Itakura_etal_ModelForMultichannelAudioSeparation_ja.pdf" target="_blank"><font color="#222222">マルチチャネル音源分離のための低ランク音源モデルとスパース重畳過程に基づくネスト型ベイズ混合・因子モデル</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Itakura_etal_ModelForMultichannelAudioSeparation_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第19回情報論的学習理論ワークショップ (IBIS2016)</em>, T2-26, 2016.

<li>板倉光佑, 坂東宜昭, 中村栄太, 糸山克寿, 吉井和佳, 河原達也<br>
<strong><a href="https://eita-nakamura.github.io/articles/Itakura_etal_MultichannelAudioSeparation_ja.pdf" target="_blank"><font color="#222222">マルチチャネル音源分離のためのネスト型基底・音源混合モデルに基づく時間周波数クラスタリング</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Itakura_etal_MultichannelAudioSeparation_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>音声研究会</em>, 信学技報, Vol. 116, No. 189, SP2016-31, pp. 25-28, 2016. <font color="#ff0080">(学生ポスター賞)</font>

<li>尾島優太, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Ojima_etal_MultipitchAnalysis_SIGMUS112.pdf" target="_blank"><font color="#222222">調・コード・音高・スペクトログラムの階層ベイズモデルに基づく多重音解析</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Ojima_etal_MultipitchAnalysis_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 6, pp. 1-8, 2016. <font color="#ff0080">(情報処理学会山下記念研究賞)</font>

<li>錦見亮, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_BayesianSemiBeatSynchronousHMM_SIGMUS112.pdf" target="_blank"><font color="#222222">歌声F0軌跡に対する音符推定のためのベイジアン準ビート同期HMM</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_BayesianSemiBeatSynchronousHMM_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 7, pp. 1-7, 2016.

<li>地曳はるか, 齋藤康之, 中村栄太, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/Jibiki_etal_ScorePageTurning_SIGMUS112.pdf" target="_blank"><font color="#222222">頷き動作による自動譜めくりシステムでの合図とリズムノリの判別</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Jibiki_etal_ScorePageTurning_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 12, pp. 1-5, 2016.

<li>佐藤陸, 中村栄太, 齋藤康之, 阿方俊, 五十嵐優, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/Sato_etal_VerticalLineNotation_SIGMUS112.pdf" target="_blank"><font color="#222222">タテ線譜と初心者向けピアノ運指のSMF からの自動生成</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Sato_etal_VerticalLineNotation_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 13, pp. 1-6, 2016.

<li>長野亜美, 齋藤康之, 中村栄太, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nagano_etal_TempoControlForAutomaticAccompaniment_SIGMUS112.pdf" target="_blank"><font color="#222222">演奏者の楽譜の休止区間における自動伴奏のテンポ制御</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nagano_etal_TempoControlForAutomaticAccompaniment_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 17, pp. 1-6, 2016.

<li>吉井和佳, 中村栄太, 糸山克寿, 後藤真孝<br>
<strong><a href="https://eita-nakamura.github.io/articles/Yoshii_etal_NMFvsPLCA_SIGMUS112.pdf" target="_blank"><font color="#222222">NMF vs PLCA: 多重音生成過程に対する無限因子モデルと無限混合モデル</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Yoshii_etal_NMFvsPLCA_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 21, pp. 1-10, 2016.

<li>中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscription_SIGMUS112.pdf" target="_blank"><font color="#222222">音型の反復と変形に基づく階層ベイズ音楽言語モデルとMIDI演奏のリズム採譜への応用</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_RhythmTranscription_SIGMUS112.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第112回情報処理学会音楽情報科学研究報告</em>, Vol. 2016-MUS-112, No. 22, pp. 1-6, 2016.

<li>中村栄太, 浜中雅俊, 平田圭二, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_PGTTM_2016.pdf" target="_blank"><font color="#222222">GTTM に基づくメロディ音符列の確率的木構造モデル</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_PGTTM_2016.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第30回人工知能学会全国大会</em>, 3G4-OS-15b-4, pp. 1-3, 2016.

<li>板倉光佑, 坂東宜昭, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Itakura_etal_MultichannelAudioLocalizationAndSeparation_ja.pdf" target="_blank"><font color="#222222">音源スペクトログラムの低ランク性とスパース性を考慮したNMF-LDA に基づくマルチチャネル音源定位と音源分離</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Itakura_etal_MultichannelAudioLocalizationAndSeparation_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第78回情報処理学会全国大会</em>, 2016. <font color="#ff0080">(学生奨励賞)</font>

<li>尾島優太, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Ojima_etal_MultipitchAnalysisByHierarchicalBayesianModel_ja.pdf" target="_blank"><font color="#222222">コード進行と多重音スペクトルの階層ベイズモデルに基づく音楽音響信号の音高推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Ojima_etal_MultipitchAnalysisByHierarchicalBayesianModel_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第78回情報処理学会全国大会</em>, 2016. <font color="#ff0080">(学生奨励賞)</font>

<li>錦見亮, 中村栄太, 糸山克寿, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_NoteEstimationForSingingVoice_ja.pdf" target="_blank"><font color="#222222">ビート準同期隠れマルコフモデルに基づく歌声音高軌跡に対する音符推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nishikimi_etal_NoteEstimationForSingingVoice_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第78回情報処理学会全国大会</em>, 2016.

<li>中村栄太, Philippe Cuvillier, Arshia Cont, 小野順貴, 嵯峨山茂樹, 渡邊健二<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_HSMMによる多声MIDI楽譜追跡.pdf" target="_blank"><font color="#222222">階層的確率生成モデルによる装飾音を含む多声MIDI音楽演奏の楽譜追跡</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_HSMMによる多声MIDI楽譜追跡.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第108回情報処理学会音楽情報科学研究報告</em>, Vol. 2015-MUS-108, No. 16, pp. 1-7, 2015.

<li>中村栄太, 小野順貴, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_出力合流HMMによるリズム採譜_2014.pdf" target="_blank"><font color="#222222">出力合流隠れマルコフモデルに基づく多声部音楽のリズム採譜</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_出力合流HMMによるリズム採譜_2014.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第104回情報処理学会音楽情報科学研究報告</em>, Vol. 2014-MUS-104, No. 8, pp. 1-7, 2014.

<li>中村栄太, 小野順貴, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_etal_PianoReduction_ja.pdf" target="_blank"><font color="#222222">ピアノの両手運指モデルによる合奏曲のピアノ用自動編曲手法</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_etal_PianoReduction_ja.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第101回情報処理学会音楽情報科学研究報告</em>, Vol. 2013-MUS-101, No. 14, pp. 1-12, 2013. <font color="#ff0080">(情報処理学会山下記念研究賞)</font>

<li>中村栄太, 齋藤康之, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_出力合流HMMによる楽譜追跡と両手分離_2013.pdf" target="_blank"><font color="#222222">出力合流並列隠れマルコフモデルとその多声鍵盤音楽の楽譜追跡・両手部分離への応用</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_出力合流HMMによる楽譜追跡と両手分離_2013.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第98回情報処理学会音楽情報科学研究報告</em>, Vol. 2013-EC-27, No. 15, pp. 1-6, 2013.

<li>伊東直哉, 深山覚, 中村栄太, 齋藤大輔, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/伊東ら_楽曲構造とテンポ包絡曲線_2013.pdf" target="_blank"><font color="#222222">楽曲構造に基づくテンポ包絡曲線の生成による自動演奏表情付けと楽曲構造解析法の検討</font></a></strong> <a href="https://eita-nakamura.github.io/articles/伊東ら_楽曲構造とテンポ包絡曲線_2013.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第98回情報処理学会音楽情報科学研究報告</em>, Vol. 2013-EC-27, No. 23, pp. 1-6, 2013.

<li>中村友彦, 中村栄太, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_高速な音響入力楽譜追跡_2013.pdf" target="_blank"><font color="#222222">弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_高速な音響入力楽譜追跡_2013.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第75回情報処理学会全国大会講演</em>, Vol. 2013, No. 1, pp. 283-284, 2013. <font color="#ff0080">(学生奨励賞)</font>

<li>中村友彦, 水野優, 鈴木孝輔, 中村栄太, 樋口祐介, 深山覚, 嵯峨山茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_音響入力自動伴奏_2012.pdf" target="_blank"><font color="#222222">音楽演奏の誤りや反復に頑健な音響入力自動伴奏</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_音響入力自動伴奏_2012.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>2012年日本音響学会秋季研究発表会</em>, 2012.

<li>中村 栄太, 山本 龍一, 齋藤 康之, 酒向 慎司, 嵯峨山 茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_装飾音のモデル_2012.pdf" target="_blank"><font color="#222222">多声MIDI演奏の楽譜追跡における装飾音のモデル化と自動伴奏への応用</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_装飾音のモデル_2012.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>2012年日本音響学会秋季研究発表会</em>, 2012.

<li>中村 栄太, 山本 龍一, 酒向 慎司, 齋藤 康之, 嵯峨山 茂樹<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_多声MIDI楽譜追跡_2012.pdf" target="_blank"><font color="#222222">多声MIDI演奏の楽譜追跡における演奏の不確定性のモデル化と自動伴奏への応用</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_多声MIDI楽譜追跡_2012.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第96回情報処理学会音楽情報科学研究報告</em>, Vol. 2012-MUS-96, No. 14, pp. 1-6, 2012.

<li>中村栄太<br>
<strong>SUSY Model Discrimination at an Early Stage of LHC</strong><br>
<em>基研研究会 素粒子物理学の進展 </em>, 2011. (素粒子論研究 119(3), C47に掲載)

<li>中村栄太<br>
<strong>Discovery Potential for Low-Scale Gauge Mediation at Early LHC</strong><br>
<em>研究会「LHCが切り拓くテラスケール物理」</em>, 2010.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong>Strongly Interacting Gauge Mediation at the LHC</strong><br>
<em>18th International Conference on Supersymmetry and Unification of Fundamental Interactions (SUSY10)</em>, 2010.

<li>濱口幸一, 中村栄太, 白井智, 柳田勉<br>
<strong>Low-Scale Gauge Mediation and Composite Messenger Dark Matter</strong><br>
<em>日本物理学会第65回年次大会</em>, 2010.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong>Low-Scale Gauge Mediation and Composite Messenger Dark Matter</strong><br>
<em>17th International Conference on Supersymmetry and Unification of Fundamental Interactions (SUSY09)</em>, 2009.

<li>濱口幸一, 中村栄太, 白井智, 柳田勉<br>
<strong>LHCにおけるStrongly Interacting Gauge Mediation模型</strong><br>
<em>日本物理学会2008年秋季大会</em>, 2008.

        </ol>

        <h3 id="Seminar"><font color="#990000">Seminar Talks | 招待講演</font></h3>

        <ol class="pub" reversed>

<li><strong>Statistical Performance Model with Explicit Voice Structure and Symbolic Music Alignment</strong><br>
Talk at the Johannes Kepler University (hosted by Dr <a href="https://www.cp.jku.at/people/arzt/"><font color="#941651">Andreas Arzt</font></a> and Dr <a href="https://www.cp.jku.at/people/widmer/"><font color="#941651">Gerhard Widmer</font></a>), Linz, 6/Sep/2017.

<li><strong>Statistical Models of Musical Rhythm and Application to MIDI Transcription</strong><br>
Talk at the Utrecht University (hosted by Dr <a href="http://www.staff.science.uu.nl/~fleis102/"><font color="#941651">Anja Volk</font></a>), Utrecht, 4/Sep/2017.

<li><strong>Symbolic Music Transcription Using Statistical Music Language Models</strong><br>
Talk at the International Audio Laboratories Erlangen, Friedrich-Alexander University Erlangen-Nuremberg (hosted by Dr <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller"><font color="#941651">Meinard Müller</font></a>), Erlangen, 24/July/2017.

<li><strong>Bayesian Learning for Modelling Repeated and Modified Musical Note Patterns</strong><br>
MusICA Seminar at the University of Edinburgh (hosted by Mr <a href="http://homepages.inf.ed.ac.uk/s1331854/home.html"><font color="#941651">Andrew McLeod</font></a> and Dr <a href="http://homepages.inf.ed.ac.uk/steedman/"><font color="#941651">Mark Steedman</font></a>), Edinburgh, 21/June/2017.

<li><strong>Recent Developments in Statistical Modelling Techniques for Symbolic Music Processing</strong><br>
C4DM Seminar at the Centre for Digital Music at Queen Mary University of London, London, 10/May/2017.

<li><strong>Recent Developments of Statistical Generative Models for Musical Note Sequences</strong><br>
Invited Talk in <em>Workshop on Music Generation using Statistical Models</em> at University of the Basque Country (UPV/EHU) (hosted by Dr <a href="http://www.ehu.eus/cs-ikerbasque/conklin/"><font color="#941651">Darrell Conklin</font></a>), San Sebastian, 28/Jan/2017.

<li><strong>Rhythm Transcription of Piano Performances Based on Hierarchical Bayesian Modelling of Repetition and Modification of Musical Note Patterns</strong><br>
Invited Seminar at Universitat Pompeu Fabra (UPF), Barcelona, 15/Nov/2016.

<li><strong>Stochastic Modeling of Arbitrary Repeats and Skips in Music Performances and Score Following</strong><br>
Invited Seminar at Institut de Recherche et Coordination Acoustique/Musique (IRCAM), Paris, 16/Jan/2014.

        </ol>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Maintained by Eita Nakamura　　　　(Last updated: Sep 2022)</p>
        <h4><a href="https://eita-nakamura.github.io">Main page</a></h4>
      </footer>
    </div>

  </body>
</html>


