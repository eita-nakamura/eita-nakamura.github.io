<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Eita-nakamura.GitHub.io : ">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>中村栄太</title>

   <style>
      ul.pub {line-height: 20px;}
      ul.pub li {margin-bottom: 10px;}
    </style>

    <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-80849161-1', 'auto');
    ga('send', 'pageview');

    </script>

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">中村 栄太 <font size="6">(Eita Nakamura)</font>　　 <a href="index.html"><font size="5" color="wheat">English</font></a></h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <div>
        <img src="images/EitaNakamura_portrait.jpg" align=left height="160" alt="Picture"/>
        <div>
          <a href="http://www.jsps.go.jp/j-pd/index.html"><font color="#222222">日本学術振興会</font></a> 特別研究員 (PD) <a href="http://www.jsps.go.jp/j-pd/index.html"><img src="./images/externallink.png" height="16px" alt="External Site"></a><br>
          京都大学 大学院情報学研究科 知能情報学専攻 <a href="http://www.i.kyoto-u.ac.jp"><img src="./images/externallink.png" height="16px" alt="External Site"></a><br>
          音声メディア分野 <a href="http://sap.ist.i.kyoto-u.ac.jp"><img src="./images/externallink.png" height="16px" alt="External Site"></a><br>
          <font color="#ff7878">enakamura[at]sap.ist.i.kyoto-u.ac[dot]jp</font><br>
          <font size=4><a href="eita-nakamura_publications.html"><strong>論文と研究発表</strong></a> [<a href="http://arxiv.org/a/nakamura_e_1.html" target="_blank">arXiv</a>]</font><br>
          <a href="eita-nakamura_cv-ja.html"><strong>略歴</strong></a><br>
        </div><br>
        </div><br>

        <h3>研究の興味</h3>
        <ul>
          <li> 音楽モデルと分析
          <li> 音楽情報処理
          <li> 統計的機械学習
        </ul>

        <h3>研究トピック</h3>
        <ul>
          <li> 自動伴奏 (<a href="http://hil.t.u-tokyo.ac.jp/software/Eurydice/index-e.html">Eurydiceシステム</a>) と音楽アラインメント <a href="https://midialignment.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt="Demo"></a>
          <li> 計算論的編曲
          <li> 自動採譜 <a href="http://anonymous4721029.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt="Demo"></a> <a href="https://anonymous574868.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a>
          <li> 計算論的音楽分析と自動作曲
          <li> ピアノ運指
        </ul>


        <h3>論文と研究発表 (抜粋) </h3>
        <h5>(全てのリストは<a href="eita-nakamura_publications.html">こちら</a>。日本語の発表は<a href="eita-nakamura_publications-ja.html">こちら</a>。)</h5>
        <ul class="pub">


          <h5><font color="#990000">2018年</font></h5>

<li>Eita Nakamura, Kunihiko Kaneko<br>
<strong><a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><font color="#222222">Statistical Evolutionary Laws in Music Styles</font></a></strong> <a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<a href="https://arxiv.org/abs/1809.05832" target="_blank"><font color="#808080">[arXiv:1809.05832]</font></a>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><font color="#222222">Statistical Piano Reduction Controlling Performance Difficulty</font></a></strong> <a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<font color="#1e5064">Submitted to <em>APSIPA Transactions on Signal and Information Processing</em>.</font> <a href="https://arxiv.org/abs/1808.05006" target="_blank"><font color="#808080">[arXiv:1808.05006]</font></a>

<li>Yuta Ojima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Chord-Aware Automatic Music Transcription Based on Hierarchical Bayesian Integration of Acoustic and Language Models</font></strong><br>
<font color="#1e5064">Submitted to <em>APSIPA Transactions on Signal and Information Processing</em>.</font>

<li>Eita Nakamura, Ryo Nishikimi, Simon Dixon, Kazuyoshi Yoshii<br>
<strong><a href="./articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><font color="#222222">Probabilistic Sequential Patterns for Singing Transcription</font></a></strong> <a href="./articles/PSPForSingingTranscription_APSIPA2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, November 2018. <font color="#e95295"><strong>(Accepted)</strong></font>

<li>Yusuke Wada, Ryo Nishikimi, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Sequential Generation of Singing F0 Contours from Musical Note Sequences Based on WaveNet</font></strong><br>
<em>Proc. 10th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, November 2018. <font color="#e95295"><strong>(Accepted)</strong></font>

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><font color="#222222">Interactive Arrangement of Chords and Melodies Based on a Tree-Structured Generative Model</font></strong><br>
<em>Proc. 19th International Society for Music Information Retrieval Conference (ISMIR)</em>, September 2018. <font color="#e95295"><strong>(Accepted)</strong></font>

<li>Kazuyoshi Yoshii, Koichi Kitamura, Yoshiaki Bando, Eita Nakamura, Tatsuya Kawahara<br>
<strong><font color="#222222">Independent Low-Rank Tensor Analysis for Audio Source Separation</font></strong><br>
<em>Proc. 26th European Signal Processing Conference (EUSIPCO)</em>, September 2018. <font color="#e95295"><strong>(Accepted)</strong></font>

<li>中村栄太, Emmanouil Benetos, 吉井和佳, Simon Dixon,<br>
<strong>多重音検出とリズム量子化の統合による多声音楽の自動採譜</strong>.
<em>第120回情報処理学会音楽情報科学研究報告</em>, Vol. 2018-MUS-120, No. 19, August 2018. <font color="#ff0080">(ベストプレゼンテーション賞受賞)</font>

<li>Yasuyuki Saito, Yasuji Sakai, Yuu Igarashi, Eita Nakamura, Suguru Agata, Shigeki Sagayama<br>
<strong><font color="#222222">Automatic Music Accompaniment Technology Applied to Recreational Singing Activities at Long-Term Health-Care Facilities</font></strong><br>
<em>Proc. 3rd Computer Simulation of Musical Creativity Conference (CSMC)</em>, August 2018.

<li>Mitsuyo Hashida, Eita Nakamura, Haruhiro Katayose<br>
<strong><font color="#222222">CrestMusePEDB 2nd Edition: Music Performance Database with Phrase Information</font></strong><br>
<em>Proc. 15th Sound and Music Computing Conference (SMC)</em>, July 2018.

<li>Eita Nakamura, Emmanouil Benetos, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="./articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><font color="#222222">Towards Complete Polyphonic Music Transcription: Integrating Multi-Pitch Detection and Rhythm Quantization</font></a></strong> <a href="./articles/AudioAndMIDITranscription_ICASSP2018.pdf" target="_blank"><img src="./images/pdf.png" height="18px"></a><br>
<em>Proc. 43rd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, April, 2018.

<li>Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><font color="#222222">Generative Statistical Models with Self-Emergent Grammar of Chord Sequences</font></a></strong> <a href="https://arxiv.org/pdf/1708.02255.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 47, No. 3, pp. 226–248, 2018. <a href="https://arxiv.org/abs/1708.02255" target="_blank"><font color="#808080">[arXiv:1708.02255]</font></a>

<li>Kousuke Itakura, Yoshiaki Bando, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara<br>
<strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><font color="#222222">Bayesian Multichannel Audio Source Separation Based on Integrated Source and Spatial Models</font></a></strong> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8276582" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2789320" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 26, No. 4, pp. 1–16, 2018. <a href="./citations/2018BayesianMNMF.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

          <h5><font color="#990000">2017年以前</font></h5>

<li>Eita Nakamura, Kazuyoshi Yoshii, Haruhiro Katayose<br>
<strong><a href="./articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><font color="#222222">Performance Error Detection and Post-Processing for Fast and Accurate Symbolic Music Alignment</font></a></strong> <a href="./articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://midialignment.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 347-353, 2017.

<li>Eita Nakamura, Kazuyoshi Yoshii, Simon Dixon<br>
<strong><a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><font color="#222222">Note Value Recognition for Piano Transcription Using Markov Random Fields</font></a></strong> <a href="https://arxiv.org/pdf/1703.08144.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2722103" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a> <a href="https://anonymous574868.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 9, pp. 1846–1858, 2017. <a href="https://arxiv.org/abs/1703.08144" target="_blank"><font color="#808080">[arXiv:1703.08144]</font></a> <a href="./citations/2017NoteValueRecognition.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices</font></a></strong> <a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2662479" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a> <a href="http://anonymous4721029.github.io/demo.html" target="_blank"><img src="./images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 4, pp. 794-806, 2017. <a href="https://arxiv.org/abs/1701.08343" target="_blank"><font color="#808080">[arXiv:1701.08343]</font></a> <a href="./citations/2017PolyphonicRhythmTranscription.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii<br>
<strong><a href="./articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><font color="#222222">Rhythm Transcription of MIDI Performances Based on Hierarchical Bayesian Modelling of Repetition and Modification of Musical Note Patterns</font></a></strong> <a href="./articles/Nakamura_etal_RhythmTranscriptionBasedOnHierarchicalBayesianModellingOfRepetitionAndModification_EUSIPCO2016.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a><br>
<em>Proc. 24th European Signal Processing Conference (EUSIPCO)</em>, pp. 1946-1950, 2016.

<li>Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><font color="#222222">Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips</font></a></strong> <a href="https://arxiv.org/pdf/1512.07748v1.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://dx.doi.org/10.1109/TASLP.2015.2507862" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 24, No. 2, pp. 329-339, 2016. <a href="https://arxiv.org/abs/1512.07748" target="_blank"><font color="#808080">[arXiv:1512.07748]</font></a> <a href="./citations/2016AudioScofo.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama, Kenji Watanabe<br>
<strong><a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><font color="#222222">A Stochastic Temporal Model of Polyphonic MIDI Performance with Ornaments</font></a></strong> <a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.tandfonline.com/doi/full/10.1080/09298215.2015.1078819" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 44, No. 4, pp. 287-304, 2015. <a href="https://arxiv.org/abs/1404.2314" target="_blank"><font color="#808080">[arXiv:1404.2314]</font></a> <a href="./citations/2014OrnamentModel.txt" target="_blank"><img src="./images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><font color="#222222">Automatic Piano Reduction from Ensemble Scores Based on Merged-Output Hidden Markov Model</font></a></strong> <a href="./articles/Nakamura-Sagayama_AutomaticPianoReduction_ICMC2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://quod.lib.umich.edu/i/icmc/bbp2372.2015.060/" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 41st International Computer Music Conference (ICMC)</em>, pp. 298-305, 2015.

<li>Eita Nakamura, Shinji Takaki<br>
<strong><a href="./articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><font color="#222222">Characteristics of Polyphonic Music Style and Markov Model of Pitch-Class Intervals</font></a></strong> <a href="./articles/Nakamura-Takaki_PolyphonicMusicStyleAndPCIntervals_MCM2015.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://link.springer.com/chapter/10.1007/978-3-319-20603-5_10" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 5th Mathematics and Computation in Music (MCM)</em>, pp. 109-114, 2015.

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama<br>
<strong><a href="./articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><font color="#222222">Merged-Output HMM for Piano Fingering of Both Hands</font></a></strong> <a href="./articles/Nakamura_etal_MergedOutputHMMForPianoFingering_ISMIR2014.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T096_251_Paper.pdf" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Proc. 15th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 531-536, 2014.

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><font color="#222222">Decaying Dark Matter Baryons in a Composite Messenger Model</font></a></strong> <a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><img src="./images/pdf.png" height="18px" alt=""></a> <a href="http://www.sciencedirect.com/science/article/pii/S0370269309003013" target="_blank"><img src="./images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 674, pp. 299-302, 2009. <a href="https://arxiv.org/abs/0811.0737" target="_blank"><font color="#808080">[arXiv:0811.0737]</font></a>

        </ul>


        <h3>デモ動画</h3>

      <p><div style="float:left;margin:5px 5px 10px 5px;">
     Eurydiceのデモ (MIDI入力)<br>
     <object classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" width="400" height="300" type="application/x-shockwave-flash">
     <param name="movie" value="http://www.youtube.com/v/KgnR2BzrafU"/>
     <param name="wmode" value="transparent"/>
     <embed src="http://www.youtube.com/v/KgnR2BzrafU" width="400" height="300"
     pluginspage="http://www.macromedia.com/go/getflashplayer" wmode="transparent" type="application/x-shockwave-flash" />
     </object>
     </div>
      <div style="float:left;margin:5px 5px 10px 5px;">
     Eurydiceのデモ (音響入力) <br>
     <object classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" width="400" height="300" type="application/x-shockwave-flash">
     <param name="movie" value="http://www.youtube.com/v/fW6VKiC4k34"/>
     <param name="wmode" value="transparent"/>
     <embed src="http://www.youtube.com/v/fW6VKiC4k34" width="400" height="300）" 
     pluginspage="http://www.macromedia.com/go/getflashplayer" wmode="transparent" type="application/x-shockwave-flash" />
     </object>
     </div>
     <div style="clear:both;"></div></p>


        <h3>連絡先</h3>
          中村 栄太<br>
          〒606-8501 京都府京都市左京区吉田本町 京都大学総合研究7号館417号室<br>
          <strong>Eメール:</strong> enakamura[at]sap.ist.i.kyoto-u.ac[dot]jp<br>
          <strong>電話:</strong> 075-753-4952<br>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Maintained by Eita Nakamura　　　　(最終更新: 2018年9月)</p>
      </footer>
    </div>

  </body>
</html>

