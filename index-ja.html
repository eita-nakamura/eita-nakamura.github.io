<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Eita-nakamura.GitHub.io : ">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>中村栄太</title>

    <style>
      ul.pub {line-height: 20px;}
      ul.pub li {margin-bottom: 10px;}


.msr_newslist01 li {
  width: 90%;
  border-bottom: 1px solid #AAAAAA;
  font-size: 14px;
  list-style-type: none;
}
.msr_newslist01 li a {
  box-sizing: border-box;
  color: #000000;
  display: table;
  padding: 5px;
  text-decoration: none;
  transition: 0.2s ease-in-out;
  -o-transition: 0.2s ease-in-out;
  -moz-transition: 0.2s ease-in-out;
  -webkit-transition: 0.2s ease-in-out;
  width: 100%;
}
.msr_newslist01 li a:hover {
  background: #EEEEEE;
  text-decoration: none;
}
.msr_newslist01 li div {
  display: table-cell;
  width: 144px;
  vertical-align: middle;
}
.msr_newslist01 li p {
  display: table-cell;
  padding-left: 20px;
  vertical-align: middle;
}

/* 時間の設定 */
ul.msr_newslist01 li time {
  display: table-cell;
  vertical-align: top;
  width: 90px;
}

/* カテゴリの設定 */
.msr_newslist01 li .cat01 {
  background-color: #143958;
  border-radius: 1px;
  color: #FFFFFF;
  font-size: 9px;
  padding: 0 2px;
  text-align: center;
  width: 50px;
}

    </style>

    <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-80849161-1', 'auto');
    ga('send', 'pageview');

    </script>

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">中村 栄太 <font size="6">(Eita Nakamura)</font>　　 <a href="https://eita-nakamura.github.io/index.html"><font size="5" color="wheat">To English</font></a></h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <div>
        <img src="https://eita-nakamura.github.io/images/EitaNakamura_portrait.jpg" align=left height="160" alt="Picture"/>
        <div>
          <font size=3>准教授<br>
          九州大学 <a href="https://www.isee.kyushu-u.ac.jp/" target="_blank">大学院システム情報科学研究院</a></font><br>
          nakamura[at]inf.kyushu-u.ac[dot]jp<br>
          <font size=4><a href="https://eita-nakamura.github.io/eita-nakamura_publications.html"><strong>論文と研究発表</strong></a> [<a href="https://arxiv.org/a/nakamura_e_1.html" target="_blank">arXiv</a>] [<a href="https://scholar.google.co.jp/citations?user=wQRi9NEAAAAJ&hl=ja" target="_blank">Google Scholar</a>]</font><br>
          <a href="https://eita-nakamura.github.io/eita-nakamura_cv-ja.html"><strong>略歴</strong></a><br>
        </div><br>
        </div><br>

        <h3>お知らせ</h3>
        <ul class="msr_newslist01">
          <li></li>
          <li>
            <a href="https://www.kyoto-be.ne.jp/toyosato-es/cms/?p=1197" target="_blank">
            <div>
              <time datetime="2023-12-18">2023/12/18</time>
              <p class="cat01">講演</p>
            </div>
            <p>京都府綾部市立豊里小学校で特別授業をしました。</p>
            </a>
          </li>          <li>
            <a href="https://cmmr2023.gttm.jp/awards/" target="_blank">
            <div>
              <time datetime="2023-11-17">2023/11/17</time>
              <p class="cat01">受賞</p>
            </div>
            <p>CMMR 2023でBest Paper Awardを受賞しました。</p>
            </a>
          </li>
          <li>
            <a href="https://www.apsipa2023.org/award.html" target="_blank">
            <div>
              <time datetime="2023-11-03">2023/11/3</time>
              <p class="cat01">受賞</p>
            </div>
            <p>APSIPA ASC 2023でBest Paper Award (2nd place)を受賞しました。</p>
            </a>
          </li>
          <li>
            <a href="https://www.youtube.com/watch?v=dgwOB9mOCt8" target="_blank">
            <div>
              <time datetime="2023-08-27">2023/8/27</time>
              <p class="cat01">報道</p>
            </div>
            <p>自動ブラスバンド編曲に関する研究が朝日新聞デジタルで紹介されました。</p>
            </a>
          </li>
<!--          <li>
            <a href="https://doi.org/10.1098/rsos.220516" target="_blank">
            <div>
              <time datetime="2022-11-2">2022/11/2</time>
              <p class="cat01">論文</p>
            </div>
            <p>我々の論文 “Dynamic cluster structure and predictive modelling of music creation style distributions” がRoyal Society Open Science誌から出版されました。</p>
            </a>
          </li>-->
          <li>
            <a href="https://doi.org/10.5281/zenodo.6642461" target="_blank">
            <div>
              <time datetime="2022-6-17">2022/06/17</time>
              <p class="cat01">公開</p>
            </div>
            <p>演歌のメロディー統計量のデータセットを公開しました。</p>
            </a>
          </li>
<!--          <li>
            <a href="https://www.youtube.com/watch?v=YiWmj1DEcMY&t=1300s" target="_blank">
            <div>
              <time datetime="2022-6-11">2022/06/11</time>
              <p class="cat01">発表</p>
            </div>
            <p>京都大学白眉センター主催「鏡プロジェクト」で音楽の進化実験の研究紹介をしました。</p>
            </a>
          </li>-->
<!--          <li>
            <a href="https://www.yomiuri.co.jp/science/20210904-OYT1T50177/" target="_blank">
            <div>
              <time datetime="2021-9-4">2021/09/04</time>
              <p class="cat01">報道</p>
            </div>
            <p>自動採譜の研究成果が読売新聞で取り上げられました。</p>
            </a>
          </li>-->
          <li>
            <a href="https://creevo-music.com" target="_blank">
            <div>
              <time datetime="2021-5-3">2021/05/03</time>
              <p class="cat01">公開</p>
            </div>
            <p>進化する自動作曲システム「CREEVO」を公開しました。入力した歌詞に対して、多様なスタイルのメロディーを自動作曲できます。機能などは逐次更新していきます。</p><figure src="float: right;"><img src="https://eita-nakamura.github.io/images/logo_mono_v_compact_green.png" height="80px" alt="" style="top:0px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 10px; border: none;"></figure>
            </a>
          </li>
          <li>
            <a href="https://beam.kisarazu.ac.jp/~saito/research/PianoFingeringDataset/index-ja.html" target="_blank">
            <div>
              <time datetime="2019-6-29">2019/06/29</time>
              <p class="cat01">公開</p>
            </div>
            <p>ピアノ運指データセット「PIGデータセット」を公開しました。学術目的であれば、登録をするだけで無償で利用できます。</p><figure src="float: right;"><img src="https://eita-nakamura.github.io/images/PIGDatasetLogo-1.png" height="80px" alt="" style="top:0px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 10px; border: none;"></figure>
            </a>
          </li>
        </ul>

        <h3>研究の興味</h3>
        <ul>
          <li> 知能の数学モデル
          <li> 文化進化
          <li> 統計学習と機械学習
          <li> 統計物理と進化動力学
          <li> 音楽情報処理
        </ul>

        <h3>研究トピック</h3>

        <div style="position:relative; width:800px; height:140px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <img src="https://eita-nakamura.github.io/images/MusicEvolution.jpg" height="130px" alt="" style="top:5px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 0px; border:1px solid rgb(200,200,200);">
          <div style="position:absolute; top:10px; left:330px; width:470px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">音楽の進化</div>
            <strong>音楽のスタイルは時代とともに変わります。それはどのように、なぜ変わるのか？未来の音楽スタイルを予測することはできるか？</strong>我々は、計算機を用いて音楽データの分析をしつつ、音楽創作過程と社会的選択の数理モデルに基づいて音楽の時代変化を調べています。
          </div>
        </div>

        <div style="position:relative; width:800px; height:180px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <iframe width="300" height="180" src="https://www.youtube.com/embed/1FBBOjdziG4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          <div style="position:absolute; top:10px; left:330px; width:450px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">自動音楽生成</div>
            <strong>コンピューターで音楽を作曲できるだろうか？</strong>我々は、統計学習と最適化の観点から音楽創作を調べています。どのように各々の音楽スタイルが形成され伝達されるか、そして音楽的創造性における<strong>能動的で動的な統計学習</strong>の役割に興味を持っています。<br>
            <div style="font-size:5pt;">　</div>
            <strong><a href="https://melodyarrangement.github.io/demo-ja.html" target="_blank">メロディーのスタイル変換</a></strong>　　
            <strong><a href="https://pianoarrangement.github.io/demo.html" target="_blank">ピアノ編曲</a></strong>
          </div>
        </div>

        <div style="position:relative; width:800px; height:162px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <a href="https://audio2score.github.io/index-ja.html" target="_blank"><img src="https://eita-nakamura.github.io/images/AutomaticMusicTranscription_light.jpg" height="160px" alt="" style="top:0px; left:20px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 0px; border:1px solid rgb(200,200,200);"></a>
          <div style="position:absolute; top:10px; left:330px; width:450px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">自動採譜</div>
            訓練された音楽家は聞いた音楽を楽譜で表すことができます。この能力を模倣する計算論的手法を調べています。自動採譜は音楽音響信号を記号領域で分析するための<strong>重要な実験手法</strong>です。<br>
            <div style="font-size:5pt;">　</div>
            <a href="https://anonymous4721029.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt="Demo"></a> <a href="https://anonymous574868.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a>　　
            <strong><a href="https://amtevaluation.github.io/" target="_blank">自動採譜評価尺度 (MUSTER)</a></strong>
          </div>
        </div>

        <div style="position:relative; width:800px; height:180px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <iframe width="300" height="180" src="https://www.youtube.com/embed/KgnR2BzrafU?start=167" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          <div style="position:absolute; top:10px; left:330px; width:450px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">自動伴奏・合奏</div>
            <strong>コンピューターは音楽を聞いて人間と合奏できるだろうか？</strong>我々は、人間の演奏を理解して人間と一緒に合奏するための方法を調べています。音楽演奏の多様な側面（テンポ変動、誤り、弾き直しと弾き飛ばし、装飾音など）を研究しています。<br>
            <div style="font-size:5pt;">　</div>
            <strong><a href="http://hil.t.u-tokyo.ac.jp/software/Eurydice/index-e.html">Eurydiceシステム</a></strong>
          </div>
        </div>

        <div style="position:relative; width:800px; height:160px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <a href="https://statpianofingering.github.io/FingeringEstimator.html" target="_blank"><img src="https://eita-nakamura.github.io/images/PianoFingering.png" width="300px" alt="" style="top:5px; left:0px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 0px; border:1px solid rgb(200,200,200);"></a>
          <div style="position:absolute; top:10px; left:330px; width:450px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">ピアノ運指</div>
            運指はピアノ演奏者にとって基礎的な技能ですが、適切な運指を見つける原理は科学的にはよく理解されていません。我々は、<strong>最適なピアノ運指を定式化して探索する</strong>ための計算モデルを構築しています。また、<strong>演奏難易度の測定法</strong>を調べています。<br>
            <a href="https://beam.kisarazu.ac.jp/research/PianoFingeringDataset-j/" target="_blank"><img src="https://eita-nakamura.github.io/images/PIGDatasetLogo-2.png" height="20px" alt="https://beam.kisarazu.ac.jp/research/PianoFingeringDataset-j/"></a>
          </div>
        </div>

        <div style="position:relative; width:800px; height:140px; margin: 20px 20px 20px 20px; padding: 0px 0px 0px 0px;">
          <a href="https://midialignment.github.io/score-performance-match-editor/ScorePerformanceMatchEditor.html" target="_blank"><img src="https://eita-nakamura.github.io/images/SymbolicMusicAlignment.jpg" height="140px" alt="" style="top:0px; left:25px; box-shadow: 0 0 0px #ebebeb; margin: 0px 0px 0px 0px; border:1px solid rgb(200,200,200);"></a>
          <div style="position:absolute; top:10px; left:330px; width:450px; height:120px; font-weight:300; text-align:justify;">
            <div style="font-size:16pt; font-weight:600; margin: 0px 0px 5px 0px;">音楽の記号的整合</div>
            ある楽曲の2つの記号表現（MIDI録音と対応する楽譜など）を音符レベルで比較する方法を調べています。演奏表情を定量的に分析したり、2つのバージョンの音楽の類似性を測る際に用いられます。<br>
            <strong><a href="https://midialignment.github.io/demo.html" target="_blank">ソフトウェアとデモ</a></strong>
          </div>
        </div>

        <div style="font-size:10pt;">　</div>



        <h3>論文と研究発表 (抜粋) </h3>
        <h5>(<a href="https://eita-nakamura.github.io/eita-nakamura_publications.html">全てのリストを見る</a>)</h5>
        <ul class="pub">

          <h5><font color="#990000">2023年以降</font></h5>

<li>中村栄太, 齋藤康之<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_絵画色彩スタイル進化_2024.pdf" target="_blank"><font color="#222222">絵画芸術における色彩スタイルの文化進化モデルに基づく創作者の影響度推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_絵画色彩スタイル進化_2024.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.iieej.org/journal/iieej-vol-53-no-1/" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>画像電子学会誌</em>, Vol. 53, 1, pp. 19-27, Feburary 2024.

<li>Ryota Nakajima, Arata Shirakami, Hayato Tsumura, Kouki Matsuda, Eita Nakamura, Masanori Shimono<br>
<strong><a href="https://doi.org/10.1038/s42003-023-05453-2" target="_blank"><font color="#222222">Mutual generation in neuronal activity across the brain via deep neural approach, and its network interpretation</font></a></strong> <a href="https://doi.org/10.1038/s42003-023-05453-2" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>Communications Biology</em>, Vol. 6, 1105, 2023.

<li>Takuto Nabeoka, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nabeoka_BandOrchestration_CMMR2023.pdf" target="_blank"><font color="#222222">Automatic orchestration of piano scores for wind bands with user-specified instrumentation</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nabeoka_BandOrchestration_CMMR2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a> <a href="https://nabeshinabe.github.io/PianoToBrassBand_nabeoka/demo.html" target="_blank"><button class="MyBtn PinkBtn">Demo</button></a> <a href="https://www.youtube.com/watch?v=dgwOB9mOCt8" target="_blank"><button class="MyBtn PinkBtn">Video</button></a> <a href="https://www.asahi.com/articles/ASR8N5V2PR6YPLBJ004.html?iref=pc_rensai_short_1910_article_5" target="_blank"><button class="MyBtn GreenBtn">Media</button></a><br>
<em>Proc. 16th International Symposium on Computer Music Multidisciplinary Research (CMMR)</em>, pp. 387-394, November 2023.

<li>Eita Nakamura, Tim Eipert, Fabian C. Moss<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_PlainChantAnalysis_CMMR2023.pdf" target="_blank"><font color="#222222">Historical changes of modes and their substructure modeled as pitch distributions in plainchant from the 1100s to the 1500s</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_PlainChantAnalysis_CMMR2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 16th International Symposium on Computer Music Multidisciplinary Research (CMMR)</em>, pp. 450-461, November 2023.

<li>Eita Nakamura<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_EvolutionOfChordProgression_CMMR2023.pdf" target="_blank"><font color="#222222">Computational analysis of selection and mutation probabilities in the evolution of chord progressions</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_EvolutionOfChordProgression_CMMR2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 16th International Symposium on Computer Music Multidisciplinary Research (CMMR)</em>, pp. 462-473, November 2023. <font color="#ff0080">(Best Paper Award)</font>

<li>Daichi Kamakura, Takehisa Ooyama, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Kamakura_MultitaskDrumTranscription_APSIPA_2023.pdf" target="_blank"><font color="#222222">Joint drum transcription and metrical analysis based on periodicity-aware multi-task learning</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Kamakura_MultitaskDrumTranscription_APSIPA_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)</em>, pp. 145-151, November 2023.

<li>Daichi Kamakura, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Kamakura_CTC2_APSIPA_2023.pdf" target="_blank"><font color="#222222">CTC2: End-to-end drum transcription based on connectionist temporal classification with constant tempo constraint</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Kamakura_CTC2_APSIPA_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)</em>, pp. 152–158, November 2023.

<li>Eita Nakamura, Yasuyuki Saito<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_ArtEvolution_APSIPA2023.pdf" target="_blank"><font color="#222222">Evolutionary analysis and cultural transmission models of color style distributions in painting arts</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_ArtEvolution_APSIPA2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)</em>, pp. 493–500, November 2023.

<li>Tengyu Deng, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Deng_SingingTranscriptionByCTC_APSIPA_2023.pdf" target="_blank"><font color="#222222">Audio-to-score singing transcription based on joint estimation of pitches, onsets, and metrical positions with tatum-level CTC loss</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Deng_SingingTranscriptionByCTC_APSIPA_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 15th Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)</em>, pp. 570–577, November 2023. <font color="#ff0080">(Best Paper Award (2nd place))</font>

<li>Norihiro Kato, Eita Nakamura, Kyoko Mine, Orie Doeda, Masanao Yamada<br>
<strong><a href="https://doi.org/10.1007/978-3-031-42682-7_46" target="_blank"><font color="#222222">Computational analysis of audio recordings of piano performance for automatic evaluation</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Kato_PianoPerformanceAutomaticEvaluation_ ECTEL2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 18th European Conference on Technology Enhanced Learning (ECTEL)</em>, pp. 586–592, September 2023.

<li>平松祐紀, 中川慧, 高野海斗, 中村栄太<br>
<strong>Stock to Music: 多変量株価時系列データの音楽変換</strong><br>
<em>2024年度 人工知能学会全国大会（第38回）</em>, to appear, June 2024.

<li>中村栄太<br>
<strong>音楽の生成モデルから音楽文化の生成モデルへ –– 音楽進化研究の現状と課題 ––</strong><br>
<a href="http://sigmus.jp/gmi/m044.html"><font color="#941651">計算論的生成音楽学（GMI）WG 第44回ワークショップ</font></a>にて講演, Hakodate, 11/March/2024.

<li>中村栄太<br>
<strong>知能情報学と進化科学の融合による音楽文化研究</strong><br>
<a href="https://dsaic.shiga-u.ac.jp/information/671/"><font color="#941651">滋賀大学 DS・AIイノベーション研究推進センター データサイエンスセミナー</font></a>にて講演, Hikone, 22/February/2024.

<li>古江真輝, 中村栄太, 伊藤貴之<br>
<strong>色彩スタイルにもとづく画家ネットワークの可視化</strong><br>
<em>第86回情報処理学会全国大会</em>, to appear, March 2024.

<li>中村栄太<br>
<strong><font color="#222222">創作知識の進化モデルに基づく作曲スタイルの変遷過程の分析</font></strong><br>
<em>第139回情報処理学会音楽情報科学研究報告</em>, to appear, pp. 1-6, March 2024.

<li>中村栄太, 伊藤貴之<br>
<strong><font color="#222222">TREXIV: 時刻スタンプ付き高次元データのための対話的可視化に基づくトレンド抽出手法</font></strong><br>
<em>第16回データ工学と情報マネジメントに関するフォーラム (DEIM 2024)</em>, to appear, March 2024.

<li>高橋舞, 小林未知数, 中村栄太, 大向一輝<br>
<strong><font color="#222222">MIDIピアノを用いたピアノコンクールの合格者と不合格者の演奏における拍間隔変化の比較</font></strong><br>
<em>第134回情報処理学会人文科学とコンピュータ研究報告</em>, to appear, pp. 1-5, February 2024.

<li>中村栄太<br>
<strong>機械学習と進化モデルに基づく創作文化の知能科学の可能性</strong><br>
<a href="https://www.network-science-seminar.com/activities/2023"><font color="#941651">ネットワーク科学研究会2023</font></a>にて講演, Kyoto, 24/December/2023.

<li>中村栄太<br>
<strong><font color="#222222">日本のポピュラー音楽におけるメロディー特徴量の進化分析</font></strong><br>
<em>日本ポピュラー音楽学会第35回年次大会</em>, A1, December 2023.

<li>中村栄太<br>
<strong><font color="#222222">確率的生成モデルに基づく音楽スタイル進化の選択・変異・輸入過程の推論</font></strong><br>
<em>第16回日本人間行動進化学会大会</em>, O03, December 2023.

<li>中村栄太<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村_知識参照ネットワーク推定_JPS_2023.pdf" target="_blank"><font color="#222222">階層的文化伝達モデルに基づく芸術データからの知識参照ネットワークの推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村_知識参照ネットワーク推定_JPS_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>日本物理学会第78回全国大会</em>, 16aC206-8, September 2023.

<li>中村栄太<br>
<strong><font color="#222222">拡張Bradley-Terry過程を含む文化進化モデルに基づく創作スタイルコミュニティーの共存条件の解析</font></strong> <br>
<em>2023年度日本数理生物学会年会</em>, P-14, September 2023.

<li>中村栄太, 齋藤康之<br>
<strong><font color="#222222">絵画創作スタイルの進化モデルの教師なし学習に基づく画家の影響度推定</font></strong> <br>
<em>日本進化学会第25回大会</em>, P-048, September 2023.

<li>中村栄太, 齋藤康之<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村ら_絵画の創作者影響度推定_2023.pdf" target="_blank"><font color="#222222">絵画芸術における色彩スタイルの文化進化モデルに基づく創作者の影響度推定</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村ら_絵画の創作者影響度推定_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第51回画像電子学会年次大会</em>, G1-1, pp. 1-4, August 2023.

<li>中村栄太<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村_コード進行の進化_2023.pdf" target="_blank"><font color="#222222">記号列の変異・選択モデルに基づくコード進行の進化過程の分析と予測</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村_コード進行の進化_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第138回情報処理学会音楽情報科学研究報告</em>, Vol. 2023-MUS-138, No. 5, pp. 1-7,, August 2023.

<li>中村栄太<br>
<strong>音楽文化の知能科学への機械学習と進化過程のモデルに基づくアプローチ</strong><br>
北海道大学社会科学実験研究センターコロキウムにて講演 (hosted by Dr <a href="https://lalalarakko.github.io/"><font color="#941651">Masanori Takezawa</font></a>), Sapporo, 31/July/2023.

<li>Eita Nakamura, Hitomi Kaneko, Takayuki Itoh, Kunihiko Kaneko<br>
<strong><a href="https://eita-nakamura.github.io/articles/Nakamura_ExperimentalEvolutionOfMusicStyles_ALIFE2023.pdf" target="_blank"><font color="#222222">Experimental evolution of music styles using automatic composition models</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Nakamura_ExperimentalEvolutionOfMusicStyles_ALIFE2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 2023 Conference on Artificial Life (ALIFE)</em>, pp. 660–662, July 2023.

<li>Moyu Terao, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://eita-nakamura.github.io/articles/Terao_BandToPianoScoreArrangement_ICASSP2023.pdf" target="_blank"><font color="#222222">Neural band-to-piano score arrangement with stepless difficulty control</font></a></strong> <a href="https://eita-nakamura.github.io/articles/Terao_BandToPianoScoreArrangement_ICASSP2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px"></a><br>
<em>Proc. 48th IEEE International Conference on Acoustics, Speech, and Signal Processing Conference (ICASSP)</em>, 1415, pp. 1-5, June 2023.

<li>中村栄太, 金子仁美, 伊藤貴之, 金子邦彦<br>
<strong><a href="https://eita-nakamura.github.io/articles/中村_音楽進化実験_JSAI2023.pdf" target="_blank"><font color="#222222">自動作曲を用いた音楽スタイルの進化実験における混合継承の効果</font></a></strong> <a href="https://eita-nakamura.github.io/articles/中村_音楽進化実験_JSAI2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>2023年度 人工知能学会全国大会（第37回）</em>, 1F5-GS-5-03, pp. 1-4, June 2023.

<li>鍋岡琢渡, 中村栄太, 寺尾萌夢, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/鍋岡_ブラスバンド編曲_2023.pdf" target="_blank"><font color="#222222">ピアノ譜から吹奏楽譜への楽器編成を指定可能な自動編曲</font></a></strong> <a href="https://eita-nakamura.github.io/articles/鍋岡_ブラスバンド編曲_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://nabeshinabe.github.io/PianoToBrassBand_nabeoka/demo.html" target="_blank"><button class="MyBtn PinkBtn">Demo</button></a><br>
<em>第85回情報処理学会全国大会</em>, 1T-04, March 2023. <font color="#ff0080">(学生奨励賞)</font>

<li>加藤徳啓, 峯恭子, 中村栄太, 土江田織江, 山田昌尚<br>
<strong>学習者のメタ認知と指導者の評価を考慮したピアノ練習演奏の分析</strong><br>
<em>第85回情報処理学会全国大会</em>, 5T-08, pp. 547-548, March 2023. <font color="#ff0080">(学生奨励賞)</font>

<li>Eita Nakamura<br>
<strong><font color="#222222">Music styles and models of cultural evolution involving statistical learning</font></strong><br>
<em>第136回情報処理学会音楽情報科学研究報告</em>, Vol. 2023-MUS-136, No. 10, pp. 1–1, February 2023. <font color="#ff0080"></font>

<li>鎌倉大地, 中村栄太, 吉井和佳<br>
<strong><a href="https://eita-nakamura.github.io/articles/鎌倉_ドラム採譜_2023.pdf" target="_blank"><font color="#222222">定テンポ制約付きCTCに基づく自動ドラム採譜</font></a></strong> <a href="https://eita-nakamura.github.io/articles/鎌倉_ドラム採譜_2023.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a><br>
<em>第136回情報処理学会音楽情報科学研究報告</em>, Vol. 2023-MUS-136, No. 15, pp. 1–7, February 2023. <font color="#ff0080"></font> <font color="#ff0080">(ベストプレゼンテーション賞)</font>

          <h5><font color="#990000">2022年以前</font></h5>

<li>Rajsuryan Singh, Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/2205.13923.pdf" target="_blank"><font color="#222222">Dynamic cluster structure and predictive modelling of music creation style distributions</font></a></strong> <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rsos.220516" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1098/rsos.220516" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Royal Society Open Science</em>, Vol. 9, 220516, 2022. <a href="https://arxiv.org/abs/2205.13923" target="_blank"><font color="#808080">[arXiv:2205.13923]</font></a>

<li>Eita Nakamura<br>
<strong><a href="https://arxiv.org/pdf/2102.01465.pdf" target="_blank"><font color="#222222">Conjugate Distribution Laws in Cultural Evolution via Statistical Learning</font></a></strong> <a href="https://arxiv.org/pdf/2102.01465.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1103/PhysRevE.104.034309" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physical Review E</em>, Vol. 104, 034309, 2021. <a href="https://arxiv.org/abs/2102.01465" target="_blank"><font color="#808080">[arXiv:2102.01465]</font></a>

<li>Kentaro Shibata, Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/2008.12710.pdf" target="_blank"><font color="#222222">Non-Local Musical Statistics as Guides for Audio-to-Score Piano Transcription</font></a></strong> <a href="https://arxiv.org/pdf/2008.12710.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1016/j.ins.2021.03.014" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://audio2score.github.io/" target="_blank"><button class="MyBtn PinkBtn">Demo</button></a><br>
<em>Information Sciences</em>, Vol. 566, pp. 262-280, 2021. <a href="https://arxiv.org/abs/2008.12710" target="_blank"><font color="#808080">[arXiv:2008.12710]</font></a>

<li>Eita Nakamura, Yasuyuki Saito, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><font color="#222222">Statistical Learning and Estimation of Piano Fingering</font></a></strong> <a href="https://arxiv.org/pdf/1904.10237.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1016/j.ins.2019.12.068" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://statpianofingering.github.io/demo.html" target="_blank"><button class="MyBtn GreenBtn">Web page</button></a><br>
<em>Information Sciences</em>, Vol. 517, pp. 68-85, 2020. <a href="https://arxiv.org/abs/1904.10237" target="_blank"><font color="#808080">[arXiv:1904.10237]</font></a>

<li>Eita Nakamura, Kunihiko Kaneko<br>
<strong><a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><font color="#222222">Statistical Evolutionary Laws in Music Styles</font></a></strong> <a href="https://arxiv.org/pdf/1809.05832.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.nature.com/articles/s41598-019-52380-6" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Scientific Reports</em>, Vol. 9, No. 15993, pp. 1-11, 2019. <a href="https://arxiv.org/abs/1809.05832" target="_blank"><font color="#808080">[arXiv:1809.05832]</font></a>

<li>Eita Nakamura, Kazuyoshi Yoshii<br>
<strong><a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><font color="#222222">Statistical Piano Reduction Controlling Performance Difficulty</font></a></strong> <a href="https://arxiv.org/pdf/1808.05006.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1017/ATSIP.2018.18" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://pianoarrangement.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt="Demo"></a><br>
<em>APSIPA Transactions on Signal and Information Processing</em>, Vol. 7, No. e13, pp. 1–12, 2018. <a href="https://arxiv.org/abs/1808.05006" target="_blank"><font color="#808080">[arXiv:1808.05006]</font> <a href="./citations/2018PianoReduction.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Kazuyoshi Yoshii, Haruhiro Katayose<br>
<strong><a href="https://eita-nakamura.github.io/articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><font color="#222222">Performance Error Detection and Post-Processing for Fast and Accurate Symbolic Music Alignment</font></a></strong> <a href="https://eita-nakamura.github.io/articles/EN_etal_ErrorDetectionAndRealignment_ISMIR2017.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://midialignment.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>Proc. 18th International Society for Music Information Retrieval Conference (ISMIR)</em>, pp. 347-353, 2017.

<li>Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama<br>
<strong><a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><font color="#222222">Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices</font></a></strong> <a href="https://arxiv.org/pdf/1701.08343v1.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://doi.org/10.1109/TASLP.2017.2662479" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a> <a href="https://anonymous4721029.github.io/demo.html" target="_blank"><img src="https://eita-nakamura.github.io/images/demo.png" height="18px" alt=""></a><br>
<em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Vol. 25, No. 4, pp. 794-806, 2017. <a href="https://arxiv.org/abs/1701.08343" target="_blank"><font color="#808080">[arXiv:1701.08343]</font></a> <a href="./citations/2017PolyphonicRhythmTranscription.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Eita Nakamura, Nobutaka Ono, Shigeki Sagayama, Kenji Watanabe<br>
<strong><a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><font color="#222222">A Stochastic Temporal Model of Polyphonic MIDI Performance with Ornaments</font></a></strong> <a href="https://arxiv.org/pdf/1404.2314v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.tandfonline.com/doi/full/10.1080/09298215.2015.1078819" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Journal of New Music Research</em>, Vol. 44, No. 4, pp. 287-304, 2015. <a href="https://arxiv.org/abs/1404.2314" target="_blank"><font color="#808080">[arXiv:1404.2314]</font></a> <a href="./citations/2014OrnamentModel.txt" target="_blank"><img src="https://eita-nakamura.github.io/images/citation.png" height="18px" alt=""></a>

<li>Koichi Hamaguchi, Eita Nakamura, Satoshi Shirai, Tsutomu T. Yanagida<br>
<strong><a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><font color="#222222">Decaying Dark Matter Baryons in a Composite Messenger Model</font></a></strong> <a href="https://arxiv.org/pdf/0811.0737v2.pdf" target="_blank"><img src="https://eita-nakamura.github.io/images/pdf.png" height="18px" alt=""></a> <a href="https://www.sciencedirect.com/science/article/pii/S0370269309003013" target="_blank"><img src="https://eita-nakamura.github.io/images/externallink.png" height="18px" alt=""></a><br>
<em>Physics Letters B</em>, Vol. 674, pp. 299-302, 2009. <a href="https://arxiv.org/abs/0811.0737" target="_blank"><font color="#808080">[arXiv:0811.0737]</font></a>

        </ul>
        <h5>(<a href="https://eita-nakamura.github.io/eita-nakamura_publications.html">全てのリストを見る</a>)</h5>


        <h3>連絡先</h3>
          中村 栄太<br>
          〒819-0395 福岡県福岡市西区元岡744 九州大学伊都キャンパス ウエスト4号館305室<br>
          <strong>Eメール:</strong> nakamura[at]inf.kyushu-u.ac[dot]jp<br>
          <strong>電話:</strong> 092-802-3808<br>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Maintained by Eita Nakamura　　　　(最終更新: 2024年4月)　　<img src="https://www.f-counter.net/j/46/1625719768/" alt="アクセスカウンター"></p>
      </footer>
    </div>

  </body>
</html>



